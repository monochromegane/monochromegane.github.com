<!doctype html><html><head><meta name=generator content="Hugo 0.59.0"><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=author content><title>THINKING MEGANE</title><meta name=twitter:card content="summary"><meta name=twitter:site content="@monochromegane"><meta property="og:description" content="THINKING MEGANE"><meta property="og:title" content="THINKING MEGANE"><meta property="og:url" content="https://blog.monochromegane.com/"><meta property="og:image" content="https://blog.monochromegane.com/images/ogp.png"><link rel=stylesheet href=/css/reset.css><link rel=stylesheet href="//fonts.googleapis.com/css?family=Source+Code+Pro" type=text/css><link rel=stylesheet href="//fonts.googleapis.com/css?family=Montserrat" type=text/css><link rel=stylesheet href=//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/styles/ir_black.min.css><link rel=stylesheet href=/css/text.css><link rel=stylesheet href=/css/color.css><link rel=stylesheet href=/css/layout.css><link rel=apple-touch-icon-precomposed sizes=57x57 href=/images/apple-touch-icon-57-precomposed.png><link rel=apple-touch-icon-precomposed sizes=114x114 href=/images/apple-touch-icon-114-precomposed.png><link rel=apple-touch-icon-precomposed sizes=72x72 href=/images/apple-touch-icon-72-precomposed.png><link rel=apple-touch-icon-precomposed sizes=144x144 href=/images/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=/images/favicon.ico><link rel=canonical href=https://blog.monochromegane.com/><link href=https://blog.monochromegane.com/index.xml rel=alternate type=application/rss+xml title="THINKING MEGANE"><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async>MathJax.Hub.Config({HTML:["input/TeX","output/HTML-CSS"],TeX:{Macros:{bm:["\\boldsymbol{#1}",1],argmax:["\\mathop{\\rm arg\\,max}\\limits"],argmin:["\\mathop{\\rm arg\\,min}\\limits"]},extensions:["AMSmath.js","AMSsymbols.js"],equationNumbers:{autoNumber:"AMS"}},extensions:["tex2jax.js"],jax:["input/TeX","output/HTML-CSS"],tex2jax:{inlineMath:[['$','$'],["\\(","\\)"]],displayMath:[['$$','$$'],["\\[","\\]"]],processEscapes:true},"HTML-CSS":{availableFonts:["TeX"],linebreaks:{automatic:true}}});</script></head><body><div class=header><header><h1 class=logo><a href=https://blog.monochromegane.com>THINKING MEGANE</a></h1><nav><ul class=menu><li><a href=/self-introduction/>Home</a></li><li><a href=/post/>Archives</a></li><li><a href=/diary/>Diary</a></li><li><a href=http://thinking-megane.blogspot.jp/>Old Blog</a></li></ul></nav></header></div><div class=container><div class=posts><article><div class=post><header><h1><a href=https://blog.monochromegane.com/blog/2020/05/16/bandit-algorithm-ucb1/>多腕バンディット問題におけるUCB方策を理解する</a></h1><time><div class=day><i class="fa fa-calendar-o day-icon"></i>2020-05-16</div></time></header><div class=post-inner><p>多腕バンディット問題における解法の一つであるUCB1方策では以下のスコアを各腕に対して求め、最大のものを選択する。</p><p>\[
\overline{x}_j+\sqrt{\frac{2\ln{n}}{n_j}} \tag{1}\label{eq-1}
\]</p><p>ここで、$\overline{x}_j$は腕$j$に対して観測された平均報酬、$n_j$は腕$j$が選択された回数、$n$は全体の試行回数である。
第2項は選択された回数$n_j$が少ないほど大きくなることから、評価が不確かな腕ほど積極的に探索を行う（<code>Optimism in face of uncertainty</code>）。</p><p>本エントリでは、この第2項について上記の振る舞い以上の理解を進める。</p><h1 id=確率不等式>確率不等式</h1><p>\eqref{eq-1}式は確率不等式の一種であるヘフディングの不等式に基づいたものであるため、まず確率不等式を学ぶ。
確率不等式は、確率の分布に依らない確率の近似的な評価に利用される不等式である。
簡単には、稀に発生する事象についての確率の上限を求めることができる。</p><h2 id=マルコフの不等式-markov-s-inequality>マルコフの不等式 Markov&rsquo;s inequality</h2><p>非負の確率変数$X\geq0$と任意の正数$a &gt; 0$に対して</p><p>\[
Pr \left[ X \geq a \right] \leq \frac{E[X]}{a} \tag{2}\label{eq-2}
\]</p><p>が成り立つ。\eqref{eq-2}をマルコフの不等式と呼ぶ。</p><p>この不等式を用いることで、確率変数$X$の実現値が$a$以上になる確率の上限を、確率分布に依らず期待値$E[X]$から求めることができる（ただし$a \leq E[X]$だと実用的な値にならない）。</p><p>マルコフの不等式を用いて例えば「期待値が10の確率変数で100以上が出る確率は10%以下」（$Pr \left[ X \geq 100 \right] \leq \frac{10}{100} = 0.1$）などと求めることができる。</p><p>証明は</p><p>\begin{align}
E[X] &amp;= \int_0^\infty x f(x) dx \notag \\ &amp;= \int_0^a x f(x) dx + \int_a^\infty x f(x) dx \notag \\ &amp;\geq \int_a^\infty x f(x) dx \notag \\ &amp;\geq \int_a^\infty a f(x) dx = a \int_a^\infty f(x) dx = a Pr [X \geq a] \notag \<br>\end{align}</p><p>となる。なお、2行目から3行目は、右辺第1項が$\geq 0$であるため。3行目から4行目は積分区間で最も小さい$a$を使うため。</p><h2 id=チェビシェフの不等式-chebyshev-s-inequality>チェビシェフの不等式 Chebyshev’s inequality</h2><p>確率変数$X$が期待値$E[X]=\mu$、分散$\sigma^2$を持つとき、任意の正数$a &gt; 0$に対して</p><p>\[
Pr \left[ \mid X - \mu \mid \geq a \sigma \right] \leq \frac{1}{a^2} \tag{3}\label{eq-3}
\]</p><p>が成り立つ。\eqref{eq-3}をチェビシェフの不等式と呼ぶ。</p><p>この不等式を用いることで、確率変数$X$の実現値と期待値$\mu$の差が標準偏差$\sigma$の$a$倍以上になる確率の上限を、確率分布に依らず期待値$\mu$と分散$\sigma^2$から求めることができる。</p><p>証明は、マルコフの不等式に対して$X = (X-\mu)^2$と$a=a^2\sigma^2$とおいた時、</p><p>\[
Pr[(X-\mu)^2 \geq a^2\sigma^2] \leq \frac{E[(X-\mu)^2]}{a^2\sigma^2} = \frac{\sigma^2}{a^2\sigma^2} = \frac{1}{a^2} \\ Pr[\mid X-\mu \mid \geq a\sigma] \leq \frac{1}{a^2}
\]</p><p>となる。なお、少し工夫して$a=a^2$とすると</p><p>\[
Pr[(X-\mu)^2 \geq a^2] \leq \frac{E[(X-\mu)^2]}{a^2} = \frac{\sigma^2}{a^2} \\ Pr[\mid X-\mu \mid \geq a] \leq \frac{\sigma^2}{a^2}
\]</p><p>のように、確率変数$X$の実現値と期待値$\mu$の差を標準偏差$\sigma$を使わずに表現できる。この場合例えば「期待値が10で標準偏差が5の確率変数で100以上が出る確率は0.31%未満」（$Pr[X-10 \geq 90] \leq \frac{5^2}{90^2} = 0.00308&hellip;$）などと求めることができる。</p><h2 id=ヘフディングの不等式-hoeffding-s-inequality>ヘフディングの不等式 Hoeffding’s inequality</h2><p>独立な$n$個の確率変数$X[a,b]$において平均を$\overline{X}$、期待値を$E\left[\overline{X}\right]$とおいた時、任意の正数$u &gt; 0$に対して</p><p>\[
Pr \left[\overline{X}-E\left[\overline{X}\right] \geq u\right] \leq \exp\left(-\frac{2n^2u^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\right) \tag{4}\label{eq-4}
\]</p><p>が成り立つ。\eqref{eq-4}をヘフディングの不等式と呼ぶ。</p><p>この不等式を用いることで、n個の確率変数$X$の平均と期待値の誤差が$u$以上になる（すなわち真の期待値を過大評価している）確率の上限を、確率分布に依らずに求めることができる。</p><p>同様に真の期待値を過小評価している確率の上限は、</p><p>\[
Pr \left[-\overline{X}+E\left[\overline{X}\right] \geq u\right] \leq \exp\left(-\frac{2n^2u^2}{\sum_{i=1}^{n}(b_i-a_i)^2}\right) \tag{5}\label{eq-5}
\]</p><p>であり、真の期待値に対して$u$以上の誤差が生じる確率の上限は\eqref{eq-4}と\eqref{eq-5}を合わせた、</p><p>\[
Pr \left[\mid \overline{X}-E\left[\overline{X}\right] \mid \geq u\right] = Pr \left[\overline{X}-E\left[\overline{X}\right] \geq u\right] + Pr \left[-\overline{X}+E\left[\overline{X}\right] \geq u\right] \tag{6}\label{eq-6}
\]</p><p>となる。</p><p>また、確率変数$X[a,b]$で$a=0,b=1$の時、\eqref{eq-4}より</p><p>\[
Pr \left[\overline{X}-E\left[\overline{X}\right] \geq u\right] \leq \exp\left(-\frac{2n^2u^2}{n}\right) = \exp\left(-2nu^2\right)\tag{7}\label{eq-7}
\]</p><p>同じく\eqref{eq-5}より</p><p>\[
Pr \left[-\overline{X}+E\left[\overline{X}\right] \geq u\right] \leq \exp\left(-\frac{2n^2u^2}{n}\right) = \exp\left(-2nu^2\right)\tag{8}\label{eq-8}
\]</p><p>である。証明は論文に譲る。</p><h1 id=ucb1方策>UCB1方策</h1><p>UCB1方策では、ヘフディングの不等式\eqref{eq-8}を用いて、腕$j$の報酬の期待値の信頼区間の上側の上限である\eqref{eq-1}を求める。
\eqref{eq-1}を再掲する。</p><p>\[
\overline{x}_j+\sqrt{\frac{2\ln{n}}{n_j}} \tag{1}
\]</p><p>腕$j$の報酬の期待値を$x^*_j$とすると\eqref{eq-8}は</p><p>\[
Pr \left[x^*_j \geq \overline{x}_j + u\right] \leq \exp\left(-2n_ju^2\right)\tag{9}\label{eq-9}
\]</p><p>\eqref{eq-9}は真の期待値を過小評価している確率の上限であり、これを試行回数$n$が進むごとに小さくしたいと考える。そこで右辺を$n^{-m}=\frac{1}{n^m}$とすると、</p><p>\begin{align}
\exp\left(-2n_ju^2\right) &amp;= \frac{1}{n^m} \notag \\ -2n_ju^2 &amp;= \ln{\frac{1}{n^m}} \notag \\ &amp;= \ln{1} - \ln{n^m} \notag \\ &amp;= 0 - m\ln{n} \notag \\ 2n_ju^2 &amp;= m\ln{n} \notag \\ u^2 &amp;= \frac{m\ln{n}}{2n_j} \notag \\ u &amp;= \sqrt{\frac{m\ln{n}}{2n_j}} \notag
\end{align}</p><p>が得られる。理論限界より$n$回目の試行において$1/n$の確率で各腕が選択する必要があるとされており、これに従えば$m=1$だが、論文では$m=4$としている（すなわち$u = \sqrt{\frac{2\ln{n}}{n_j}}$）。</p><p>これを\eqref{eq-9}に代入し</p><p>\[
Pr \left[x^*_j \geq \overline{x}_j + \sqrt{\frac{2\ln{n}}{n_j}}\right] \leq \frac{1}{n^4}\tag{10}\label{eq-10}
\]</p><p>よって$1/n^4$の上限において、\eqref{eq-1}のスコアを用いて報酬の期待値を最も低く見積もっているであろう腕を選択することができる。すなわち<code>Optimism in face of uncertainty</code>に従う。</p><h1 id=参考>参考</h1><ul><li><a href=https://ja.wikipedia.org/wiki/%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E3%81%AE%E4%B8%8D%E7%AD%89%E5%BC%8F>マルコフの不等式</a></li><li><a href=https://ja.wikipedia.org/wiki/%E3%83%81%E3%82%A7%E3%83%93%E3%82%B7%E3%82%A7%E3%83%95%E3%81%AE%E4%B8%8D%E7%AD%89%E5%BC%8F>チェビシェフの不等式</a></li><li><a href="https://www.youtube.com/watch?v=d-ugoDdXWrU">【大学数学】チェビシェフの不等式【確率統計】- 予備校のノリで学ぶ「大学の数学・物理」</a></li><li><a href="http://stat.inf.uec.ac.jp/lib/exe/fetch.php?media=prob:prob-9-note-and-quizes-20120614.pdf">確率論 (Probability Theory) 第 9 週</a></li><li><a href=https://en.wikipedia.org/wiki/Hoeffding%27s_inequality>Hoeffding&rsquo;s inequality</a></li><li><a href=http://repository.lib.ncsu.edu/bitstream/1840.4/2170/1/ISMS_1962_326.pdf>Hoeffding, Wassily (1963). &ldquo;Probability inequalities for sums of bounded random variables&rdquo;. Journal of the American Statistical Association. 58 (301): 13–30.</a></li><li><a href=https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf>Auer, Peter, Nicolo Cesa-Bianchi, and Paul Fischer. &ldquo;Finite-time analysis of the multiarmed bandit problem.&rdquo; Machine learning 47.2-3 (2002): 235-256.</a></li><li><a href=https://ludu-vorton.hatenablog.com/entry/2019/06/06/073000>ヘフディングの不等式(Hoeffding&rsquo;s inequality)と諸々の確率の評価の不等式</a></li><li><a href=https://qiita.com/usaito/items/ad15394547bd5daf8937>バンディットアルゴリズムで最適な介入を見つける（基本編）</a></li><li><a href=https://research.miidas.jp/2020/02/%E3%83%90%E3%83%B3%E3%83%87%E3%82%A3%E3%83%83%E3%83%88%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E7%B6%9A%E3%81%8D/>バンディットアルゴリズムの続き</a></li><li><a href=https://www.slideshare.net/nishio/1-70974083>強化学習その1</a></li><li><a href=https://www.amazon.co.jp/dp/406152917X/>バンディット問題の理論とアルゴリズム (機械学習プロフェッショナルシリーズ)</a></li></ul></div><footer class=tag><i class="fa fa-tags tag-icon"></i><ul><li><a class=tag-link href=/tags/bandit>bandit</a></li></ul><div class=clear></div></footer></div></article><article><div class=post><header><h1><a href=https://blog.monochromegane.com/blog/2020/04/29/why-fukuokago/>なぜ勉強会「だった」のか</a></h1><time><div class=day><i class="fa fa-calendar-o day-icon"></i>2020-04-29</div></time></header><div class=post-inner><p>主催するFukuoka.goでは2〜3ヶ月に一度の割合で登壇形式の勉強会を開催している。
昨今の状況を受けて前回こそYouTubeを使ってリアルタイム配信を行ったものの、この状況が続くあるいは当たり前になるならば、地域言語コミュニティをどう運営していくべきか考えないといけないだろうなと思う。</p><p><blockquote class=twitter-tweet><p lang=ja dir=ltr>Fukuoka.go#16 をそろそろやろうかなと思いつつ、オンライン開催が前提で、もはや地理的な制約もない中で、このコミュニティで本当に実現したいことを改めて考えてみるなど。さて、どう楽しみますかねえ</p>&mdash; モノクロメガネ研究員 (@monochromegane) <a href="https://twitter.com/monochromegane/status/1255359093058961412?ref_src=twsrc%5Etfw">April 29, 2020</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script></p><p>このエントリは、これまでの勉強会やカンファレンスではなぜ物理的に集合するのか、を自分の中で整理した上で、オンライン開催のありようを考える材料を見つけようとするものです。</p><h1 id=なぜ物理的に集合するのか>なぜ物理的に集合するのか</h1><p>これまでの勉強会やカンファレンスではなぜ物理的に集合していたのか。</p><p>今年、オンラインでの開催を余儀なくされた様々な勉強会やカンファレンスでは（それなりの運営の苦労はありつつも）比較的スムーズに移行できており、これはそのようなインフラが整っていたということに他ならない。
一方で、これだけのインフラがある中、必要に迫られるまでは物理的に集合していたということは、この行為になんらかの利点があると考えるのが妥当だと思う。</p><p>物理的に集合する勉強会やカンファレンスでは、登壇者の発表を聞き、質疑があり、飲食の機会が提供される。
同じ場に集ってリアルタイムに同時多発的に発生した議論によって、場には総体として大きくなった知が形成される。
参加者は、場によって増幅された知を様々な形で受け取る。
あるひとは有意義な情報として、あるひとはモチベーションとして。
想定より多くの量を得ることができる人もいれば、あまり得るものがなかった人もいるかもしれない。
主催者は、なるべくその機会を増やすべく、趣向を凝らす。</p><p>勉強会やカンファレンスというのは、興味関心を同じくするものの初対面の人たちを含む集団が限られた時間で効率よく、知の増幅を場に形成するための枠組みであると言える。</p><ul><li>発表者が資料を用意して丁寧に説明することで、「同じ事」を、</li><li>日程や会場を揃えることで、「同じタイミング」で、</li><li>質疑応答の機会や飲食による雰囲気を使って、「同じ立場」で、</li></ul><p>参加者は一緒に考え、場を作っていく。</p><p>これまでは、物理的な集合を伴う勉強会やカンファレンスを開催することで、自然とこの枠組みに乗って、知の増幅を場に形成する機会を提供できていた。
物理的な集合を伴わないオンライン開催が前提になれば、これらを達成するための仕組みを意識的に演出しなければならない（あるいは目的自体を変える？）</p><h1 id=オンライン開催は代替となるのか>オンライン開催は代替となるのか</h1><p>せっかくオンラインでやれるのだから、漠然とこれまでの勉強会の代替ではなく、目的を明確にした上で技術的に解決できるといいなと思っている。</p><p>知の増幅を場に形成するのであれば、物理的な集合を伴わないオンライン開催であっても、登壇のリアルタイム配信によって参加者が、同じことを同じタイミングで考えることは有効だろう。
実際、難しいのは、「同じ立場」の部分だと思う。</p><p>興味関心を同じくするものの初対面の人たちが短時間で気兼ねなく議論できる状態を作りたい。
明示的な質疑応答の機会はもちろん必要だろう。
それでも、議論が深くなるとき、もしくは個別化しそうな時、同じミーティングルーム内で即座に個別かつ双方向に話せるだろうか。
昨年、登壇したGopherConでは、発表後はもちろんのこと、廊下でのすれ違うタイミングで感想や質問をたくさん受けた。そういうことを再現できないだろうか。</p><p>問題意識の方向性やレベル感が同じくする人を積極的に見つけて、同じ立場の中でクラスタリングされて、その問題を本当に考えたい人が凝縮して、それぞれの知を増幅して、総体として大きくなった知が形成される。</p><p>この辺りの、集団から始まって最終的に、個と個をダイナミックにつなげる部分をなんとか解決していきたいと思う。</p><h1 id=fukuoka-goはどうするのか>Fukuoka.goはどうするのか</h1><p>どうしよう。</p><p>Fukuoka.goは長期的にみて知の増幅を地域に形成できる（といいな）というあたりを狙っているので、主催者が楽しんで継続できることを大切にしています。
色々それらしきことを述べてみたものの、主催者のモチベは単純には「僕の最近のGo取り組みで面白かったものを聞いてください。よければご飯もどうですか」だったりもするので、オンライン飲みの余興で発表、とか、登壇を動画で配信とかでもいいのかもしれない。</p></div><footer class=tag><i class="fa fa-tags tag-icon"></i><ul><li><a class=tag-link href=/tags/></a></li></ul><div class=clear></div></footer></div></article><article><div class=post><header><h1><a href=https://blog.monochromegane.com/blog/2020/04/29/wsa6_sifter/>軽量なインデックス機構を用いた全文検索ツールの高速化の検討</a></h1><time><div class=day><i class="fa fa-calendar-o day-icon"></i>2020-04-29</div></time></header><div class=post-inner><p>このエントリは、<a href=https://websystemarchitecture.hatenablog.jp/entry/2019/12/11/165624>第6回 Web System Architecture 研究会 (WSA研)</a>の予稿です。</p><h1 id=概要>概要</h1><p>コマンドラインによる全文検索ツールの検索速度は、キャッシュ機構、並列化や効率的なアルゴリズムの導入によって高速化が図られている。一方で、これらのツールは、検索対象の変更や削除への追従を避けるためインデックスの採用を行なっておらず、都度検索対象に対して全探索を行う。</p><p>全文検索ツールに対するインデックス機構の課題を整理、解決し、インデックス機構を採用することができれば、検索対象を限定した、より高速な検索が可能になると考えられることから、本稿では、軽量なインデックス機構を用いた全文検索ツールの高速化の検討を行う。</p><p>提案手法では、インデックス機構に計算量と情報量の観点で効率的に扱うことのできるブルームフィルタを採用する。 まず全ての検索対象に対してブルームフィルタを作成し、結合・転置した軽量なインデックスを生成する。 次に検索対象へのクエリを行う前にインデックスから候補を取得し、全文検索ツールがこれを検索する。 検索対象の変更や削除への追従に対しては、インデックスを都度再生成する方式を採用するが、生成の高速化により利用者が負担とすることなくこれを行える。</p><p>評価では、提案手法を組み合わせることで、全文検索ツールの検索時間が短縮することを確認する。</p><h1 id=発表スライド>発表スライド</h1><p>提案手法のアーキテクチャ、ならびに具体的な実装である<a href=https://github.com/monochromegane/sifter>monochromegane/sifter</a>とこれによる軽量・高速・汎用性についての評価は発表スライドを参照のこと。</p><script async class=speakerdeck-embed data-id=b290ecaaf9d24927b528991ac76f9c89 data-ratio=1.77777777777778 src=//speakerdeck.com/assets/embed.js></script><h1 id=まとめ>まとめ</h1><p>本研究会では軽量なインデックス機構を用いた全文検索ツールの高速化の検討とその参考実装を評価した。
インデックス機構としてブルームフィルタを用いることで少ないメモリ使用量と問い合わせの高速化が達成でき、インデックス操作のツールに分離することで任意の全文検索ツールとの連携による汎用性を備えることができた。
結果として、評価では全文検索ツールとの組み合わせにおいて大幅な検索時間の短縮を確認した。</p><p>一方で、インデックス構築時間の長さを解消することは、利用者にとっての負担の改善の観点から最優先で取り組まなければならない。
ブルームフィルタにおけるハッシュ関数のボトルネックは多く研究されていることから、これを取り込むこと、また、ハッシュ関数の実行回数を減らしながら精度を保つことができるような効率的なトークン化を調べる必要がある。
実装面ではハッシュ関数の結果は再利用できるため、キャッシュ機構の導入も効果があると考える。</p><p>今後は問い合わせ自体にオーバーヘッドが発生するようなアーキテクチャとの連携も検討し、Webシステムの分野へ研究を発展させたい。</p><h1 id=発表を終えて>発表を終えて</h1><p>今回のWSA研は初のリモート開催で新しい顔ぶれも揃い、6回目ながらに新鮮な気持ちで楽しめた。
自身の発表でも、あまり気負いすぎずに頭の中で温めていたアイディアを形にして議論として発展できればいいなぐらいで臨んだ。
結果的に、まずは発表に向けて形にして評価することで長所短所が明確になり、参加者から新しいアイディアのヒントをもらうことができた。
特に、これまでプラチナサーチャーでの全文検索の高速化は、システムコールやバッファ確保の効率化やタスクの並列化といったプログラミングの実装面でのアプローチがほとんどであったため、アルゴリズムの観点からの取り組むためのとっかかりを色々議論できたと思う。
この分野は先人の知恵が大量にある分野なので、色々勉強しつつプラチナサーチャーの進化系も考えていきたい（研究会終わった後の夜中に考えていた方法がSuffix Trieと同じだと気づいて、巨人の肩に乗るべく、まずは<a href="https://www.amazon.co.jp/gp/product/4000069748/ref=as_li_tl?ie=UTF8&amp;camp=247&amp;creative=1211&amp;creativeASIN=4000069748&amp;linkCode=as2&amp;tag=monochromeg03-22&amp;linkId=1f321dceee1ea3723f7c384f5f3460cb">高速文字列解析の世界――データ圧縮・全文検索・テキストマイニング (確率と情報の科学)</a>を注文した）</p><p>このような普段の研究から少し離れた取り組みであっても、定期的に発表を促されることで形にすることができるのはとても大切で、やりっぱなし学びっぱなしではなく一つの区切りまで考え実装することで次回以降の研究への糧となる。
Webシステムアーキテクチャに関する運用知見を研究的アプローチで前進させること興味がある方は次回開催の参加を検討してみてはいかがでしょうか。</p><ul><li><a href=https://websystemarchitecture.hatenablog.jp/entry/2017/11/16/182041>Web System Architecture研究会の発足と挨拶</a></li><li><a href=https://websystemarchitecture.hatenablog.jp/purpose>研究会の目的</a></li></ul><p>＊次回は9月の後半のようです。</p></div><footer class=tag><i class="fa fa-tags tag-icon"></i><ul><li><a class=tag-link href=/tags/wsa%E7%A0%94>WSA研</a></li></ul><div class=clear></div></footer></div></article><article><div class=post><header><h1><a href=https://blog.monochromegane.com/blog/2020/03/11/dynamic-gamma-poisson/>Dynamic Gamma-Poisson modelを試す</a></h1><time><div class=day><i class="fa fa-calendar-o day-icon"></i>2020-03-11</div></time></header><div class=post-inner><p><a href=https://speakerdeck.com/monochromegane/fukuokago15-adwin-exphist>以前のADWINのように</a>、変化する環境において適応的に振る舞うための仕組みについて調べる中で以下の論文で紹介されていたDynamic Gamma-Poissonモデルについてベイズ推定の理解を兼ねて試してみたのでメモ。</p><ul><li><a href=http://www2009.wwwconference.org/proceedings/pdf/p21.pdf>Agarwal, Deepak, Bee-Chung Chen, and Pradheep Elango. &ldquo;Spatio-temporal models for estimating click-through rate.&rdquo; Proceedings of the 18th international conference on World wide web. 2009.</a></li></ul><h1 id=ベイズ推定>ベイズ推定</h1><p>統計モデルとは</p><blockquote><p>「ある確率変数$Y$の実現値$y=\{y_1,y_2,..,y_n\}$から、$Y$が本来従う確率分布（真の分布）を推定するためのもの」</p></blockquote><p>とされている。
ベイズ推定はベイズの定理に基づいて観測したデータと過去の情報からデータの本来従う確率分布を推定する。</p><p>ベイズの定理 $p(\theta \mid y) \propto p(y \mid \theta)p(y)$ に対して右辺（尤度x事前確率）が具体的な確率値でかつ分布が数え上げられるような単純な場合は理解は比較的容易。</p><ul><li><a href=https://mathtrain.jp/bayesinfer>ベイズ推定の簡単な例と利点</a></li></ul><p>一方で、データの確率分布がパラメタによって変動するような確率質量関数や確率密度関数に従う場合、<strong>そのパラメタ（母数）の分布を推定する</strong>ことで、（分布の種類が分かっていればパラメタの推定が分布の特定になるので）データの従う確率分布を推定できる。
この時、データの分布の種類に応じた事前分布を選択することで事後分布が求めやすくなる（共役事前分布）。</p><p>このようなパラメタを推定するようなベイズ推定に関しては以下の資料が理解の助けになる。</p><ul><li><a href=https://www.slideshare.net/miyoshiyuya/ss>ベイズ統計学入門</a></li><li><a href=https://mutopsy.net/pdf/note_sta_bayesian01.pdf>ベイズ推定の初歩 二項分布を例に</a></li><li><a href=https://ocw.mit.edu/courses/mathematics/18-443-statistics-for-applications-spring-2015/lecture-notes/MIT18_443S15_LEC8.pdf>Parameter Estimation Fitting Probability Distributions Bayesian Approach</a></li></ul><p>以下、ポアソン分布のパラメタ推定を例にベイズ推定の理解を深め、これを拡張したDynamic Gamma-Poissonモデルを説明する。</p><h2 id=ポアソン分布>ポアソン分布</h2><p>単位時間に平均$\lambda$回起きる事象が単位時間に$k$回発生する分布。</p><p>平均が$\lambda$のポアソン分布を表す確率質量関数は\[P(X=k)=\frac{\lambda^{k}}{k!}\cdot e^{-\lambda}\]であり平均$E[X]$は$\lambda$となる。</p><h2 id=ポアソン分布のパラメタ-lambda-を推定する>ポアソン分布のパラメタ$\lambda$を推定する</h2><p><a href=https://ocw.mit.edu/courses/mathematics/18-443-statistics-for-applications-spring-2015/lecture-notes/MIT18_443S15_LEC8.pdf>Parameter Estimation Fitting Probability Distributions Bayesian Approach</a>のp.19の例を元に説明する。</p><ul><li>$X_1,X_2,..,X_n$ $i.i.d.$ $Poisson(\lambda)$<ul><li>単位時間に平均$\lambda$回起きる分布に従う確率変数の実現値を$n$回観測</li><li>$X_i$は0以上の整数値</li></ul></li><li>$lik(\lambda) = f(x_1, x_2,..,x_n \mid \lambda) = \prod_{i=1}^n f(x_i \mid \lambda)$<ul><li>尤度はパラメタ$\lambda$において観測した値が得られる確率（この場合は上述したポアソン分布の確率質量関数$P(X=x_i)$）</li><li>複数回観測した場合はその同時確率</li></ul></li><li>$\lambda \sim Gamma(\alpha, \nu)$<ul><li>事前分布、つまり、$\lambda$が「ある値（の範囲）」を取る確率</li><li>今回は事前分布にガンマ分布を仮定する（ポアソン分布の共役事前分布）</li><li>$\pi(\lambda)$</li></ul></li><li>$\pi(\lambda \mid x) \propto lik(\lambda) \times \pi(\lambda)$<ul><li>ベイズの定理より事後分布は尤度x事前分布で求められる</li><li>$P(x\mid\lambda)P(\lambda)$なので、$\lambda$の分布から観測値$x$が得られる確率と言える</li></ul></li><li>$Gamma(\alpha^*,\nu^*)$ with $\alpha^*=\alpha+\sum_{1}^n x_i$ and $\nu^*=\nu+n$<ul><li>上を計算すると事後分布は観測された$x$の値の合計を$\alpha$に、観測回数$n$を$\nu$に加えたものをパラメタとするガンマ分布とみなせる</li><li>観測したデータから$\lambda$の分布（確率変数が従う確率分布（分布の種類はわかっているのでそのパラメタ））を推定した</li></ul></li></ul><h1 id=dynamic-gamma-poissonモデル>Dynamic Gamma-Poissonモデル</h1><p>論文3.1によれば、クリック数$c$、閲覧数$v$、CTRを$\theta$としたときに、</p><ul><li>平均$v\theta$(=$\lambda$)である$Poisson(\lambda)$に従い観測されたクリック数から</li><li>$\theta$の事前分布に平均が$\alpha/\gamma$、分散が$\alpha/\gamma^2$である$Gamma(\alpha,\gamma)$を仮定して</li><li>$\theta$の事後分布を$Gamma(\alpha+c,\gamma+v)$として得られるとしている</li></ul><p>ただし、実際はこの推定は$\lambda$の推定であるため、CTRとして考えるために以下のように考える。</p><ul><li>$\lambda$を1閲覧($v$)の間の平均回数と考える（つまり$\lambda=1*\theta$）</li><li>1閲覧に該当する期間を閲覧数分、観測した</li><li>これによって推定された$\lambda$は$\theta$と等しくなる</li></ul><p>ここで、$Gamma$のパラメタはこれまでのクリック総数と閲覧総数であることから、$\lambda$の値が変化する場合に過去のデータに引きづられてしまい、速やかな追従を行うことができない。
論文では、Dynamic Gamma-Poissonモデルとして過去の観測結果に対する割引の概念を導入することでこれを解決する。
実現はシンプルで、割引率$(0&lt; \delta \leq1)$を導入し、事後分布を$Gamma(\delta\alpha_{t-1}+c_t,\delta\gamma_{t-1}+v_t)$のように求める。
これによって累積された過去の総数を減らし、直近のデータに重み付けが行われる。
論文中では0.95から1の間ぐらいが良い結果を得たとしている。</p><p>以下、実際に同じ条件での$\lambda$の推定を通常のGamma-PoissonモデルとDynamic Gamma-Poissonモデルで行ったものを比較する。
評価では、CTRが0.4のアイテムに対して1ステップごとに7回の閲覧が行われた際のクリック数を観測データとした。
また、20ステップ目にCTRが半分の0.2になっている。</p><p><img src=/images/2020/03/dgp.gif alt=dgp></p><p>評価期間内では通常の推定の期待値0.3程度までの追従に止まったが、Dynamicな手法ではより早く実際のCTRである0.2に近づけたことが分かる。</p><h1 id=動作確認用のコード>動作確認用のコード</h1><p>動作確認用のコードは以下にある．</p><ul><li><a href=https://gist.github.com/monochromegane/942444fdf89735e7e273d5c7126df449>dgp.py</a></li></ul><p>このような感じで利用できる．</p><pre><code class=language-sh>python dgp.py --lambda_ 0.4 --view 7 --delta 0.9
</code></pre></div><footer class=tag><i class="fa fa-tags tag-icon"></i><ul><li><a class=tag-link href=/tags/></a></li></ul><div class=clear></div></footer></div></article><article><div class=post><header><h1><a href=https://blog.monochromegane.com/blog/2020/03/03/minimum-start-for-online-event/>勉強会をオンライン配信するための必要最小限な環境構築</a></h1><time><div class=day><i class="fa fa-calendar-o day-icon"></i>2020-03-03</div></time></header><div class=post-inner><p>昨今の状況だけでなく、多様な働き方やコミュニティ（とそこで得られる情報）に接する機会を増やすためにも今後、オンライン勉強会は広がっていくと思います。
Fukuoka.goでも今回、初めて勉強会のオンライン配信を実施しました。
同様のモチベーションを持つイベントの主催者に向けて、勉強会をオンライン配信するためにやった最小限の環境構築についてまとめておきます。</p><h1 id=想定する環境>想定する環境</h1><p>オンライン勉強会には、Google Hangouts Meetなどのビデオ会議のWebサービスとYouTubeライブ配信を用います。
勉強会には、配信を行う運営者、発表を行う登壇者、発表を聞く参加者がいるとします。</p><p>登壇者はビデオ会議の画面共有によって各々のPCから発表を行います。
運営者はビデオ会議の画面と音声をYouTubeでライブ配信します。
参加者はYouTubeのライブ配信を視聴、必要に応じてコメントします。</p><p><img src=/images/2020/03/architecture.jpg alt=architecture></p><p>ビデオ会議とライブ配信のWebサービスを利用することで、Macに二つオープンソースソフトウェアをインストールするだけで、最低限の配信環境環境が整ってしまいます。ありがたい時代になりました。インターネット万歳。</p><h1 id=手順のサマリ>手順のサマリ</h1><pre><code>1. YouTubeアカウントを作成（要Googleアカウント）
2. YouTubeライブ配信を作成（初回は24時間程度待つ必要あり）
3. 配信に必要なソフトウェアをダウンロードしてインストール
  - [OBS Studio](https://obsproject.com/download)
  - [BlackHole](https://github.com/ExistentialAudio/BlackHole)
4. YouTubeエンコード配信を選択し、ストリーミングキーを発行
5. OBSにストリーミングキーを設定
6. OBSで音声ミキサーとしてBlackHoleを追加（マイク2）
  - 必要に応じてマイク(1)はミュート
7. OBSでソースにウィンドキャプチャでMeetを実行するブラウザを追加
  - ウィンドウキャプチャに必要なウィンドウが出ない場合はmacOSXのセキュリティとプライバシーでOBSが画面収録を許可されているか確認
8. macOSXの音声出力をBlackHoleに変更
9. OBSで配信開始をクリック
  - しばらく待つとYouTube側の配信ボタンが押せるようになる
10. YouTubeの配信開始をクリック
11. 配信する
  - 画面がチラつく場合はOBS Studioがウィンドウキャプチャしている画面の前面に配置されていないか確認
12. YouTubeの配信終了をクリック
13. OBSの配信終了をクリック
</code></pre><h1 id=手順の詳細>手順の詳細</h1><p>以下、上記手順についての詳しい説明です。</p><p>なお、配信のための環境構築には配信の専用機を用意するのが一番楽でしょう。
以下、配信の専用機としてMacBook Pro (15-inch, 2019) macOS Catalina(10.15.3)を用いています。</p><p>また、配信に利用するPCは有線によるネットワーク接続をおすすめします。</p><h2 id=youtubeアカウントを作成>YouTubeアカウントを作成</h2><p>持っていなければ作成しましょう。Googleのアカウントが必要です。</p><h2 id=youtubeチャンネルを作成>YouTubeチャンネルを作成</h2><p>ライブ配信をするチャンネルを作成しましょう。</p><h2 id=youtubeライブ配信を作成>YouTubeライブ配信を作成</h2><p><code>ライブ配信を開始</code> ボタンからライブ配信を登録します。
初めてライブ配信を登録する場合は、<strong>24時間待つ必要がある</strong>ため、余裕を持って登録しましょう。</p><p><img src=/images/2020/03/youtube_start.jpg alt=start></p><p><code>エンコーダ配信</code> タブから、タイトル、公開範囲、カテゴリを指定します。
作成後、ライブ配信のための <code>ストリームキー</code> が取得できるため控えておきます。</p><h2 id=配信に必要なソフトウェアをダウンロードしてインストール>配信に必要なソフトウェアをダウンロードしてインストール</h2><p>ライブ配信をサポートしてくれる <code>OBS Studio</code> と仮想オーディオデバイスを作成するための <code>BlackHole</code> をインストールします。</p><ul><li><a href=https://obsproject.com/download>OBS Studio</a></li><li><a href=https://github.com/ExistentialAudio/BlackHole>BlackHole</a></li></ul><p>＊BlackHoleはmacOSから出力される音声（今回の場合ではビデオ会議の音声）をYouTubeで配信するために利用します。配信機がWindowsであればデスクトップ音声をキャプチャできるそうなのですがmacOSではできないため、BlackHoleで仮想オーディオデバイスを作成して回避します。</p><p>以下、OBS Studioは <code>24.0.6 (64 bit)</code>、BlackHoleは <code>v0.2.6</code>を利用した場合の手順となります。</p><h2 id=obs-studioでストリームキーの設定>OBS Studioでストリームキーの設定</h2><ol><li>設定 -&gt; 配信</li><li>サービスにYouTube/YouTube Gamingを選択</li><li>サーバーにPrimary YouTube ingest serverを選択</li><li>ストリームキーに先ほど控えておいた値を入力</li></ol><h2 id=obs-studioで音声の設定>OBS Studioで音声の設定</h2><ol><li>設定 -&gt; 音声</li><li>マイク音声 2にBlackHole 16chを選択</li></ol><p>必要に応じてマイク音声(1)は無効、もしくは配信時にミュートしておくと余計な音声が入らずに便利。</p><h2 id=obs-studioで配信ソースの設定-待ち受け画面>OBS Studioで配信ソースの設定（待ち受け画面）</h2><p>配信の準備中やビデオ会議の画面を表示したくない時の待ち受け画像のシーンを準備しておくと便利。</p><ol><li>シーンを選択し、画像ソースを追加</li><li>新規作成からOKで画像プロパティが表示される</li><li>画像ファイルを選択してOK</li></ol><h2 id=obs-studioで配信ソースの設定-ビデオ会議画面>OBS Studioで配信ソースの設定（ビデオ会議画面）</h2><p>タブブラウザの場合、ビデオ会議のウィンドウは分けておくと便利。</p><ol><li>待ち受け画面とシーンを分けるのでシーンを追加</li><li>新しいシーンを選択し、ウィンドウキャプチャソースを追加</li><li>新規作成からOKでウィンドウキャプチャプロパティが表示される</li><li>ビデオ会議のウィンドウを選択</li></ol><p>ウィンドウに起動中のアプリが表示されない場合は、macOSの設定-&gt;セキュリティとプライバシーから画面収録に対してOBSの許可がチェックついているか確認のこと。</p><h2 id=obs-studioの設定確認>OBS Studioの設定確認</h2><p>ここまででOBS Studioの下部は以下のような設定になっているはずです。</p><p><img src=/images/2020/03/obs_studio.jpg alt=obs></p><p><code>シーン</code>は静止画用、<code>シーン2</code>がビデオ会議の画像用です。
僕の環境ではシーン2に、ビデオ会議の画面とTwitterの画面を二つ並べて表示するようにしたので、ウィンドウキャプチャのソースが2つあります。</p><p>また、音声ミキサーは<code>マイク2</code>をミュートにすれば、ビデオ会議の音声が配信に乗らなくなります。</p><h2 id=macosの音声出力をblackholeに変更>macOSの音声出力をBlackHoleに変更</h2><p>ビデオ会議の音声をBlackHole経由でOBS Studioに渡せるようにします。
macOSの設定-&gt;サウンドから出力タブでBlackHoleを選択します。</p><ul><li>＊macOSの音声出力をBlackHoleに変更するとmacOSからは音声が聞こえなくなります。音声も聞きたい場合は、macOSのユーティリティ-&gt;オーディオ装置から複数出力装置を作成し、MacBookのスピーカーとBlackHoleに同時に出力できるデバイスを作成してください。そしてmacOSの音声出力をBlackHoleではなく、複数出力装置を選びます（OBS StudioはBlackHoleの入力側を利用するのでそのままで良いです）。
Ref: <a href=https://github.com/ExistentialAudio/BlackHole/wiki/Multi-Output-Device>https://github.com/ExistentialAudio/BlackHole/wiki/Multi-Output-Device</a>
手元では、複数出力装置について外部オーディオ装置との相性が悪かったため利用していません（配信の専用機なのでここから音が聞こえる必要はなく現在のところBlackHoleを直接利用で困ってない）
もし、外部オーディオ装置も含めて高度な設定が必要な場合は、LadioCastなどのソフトウェアミキサーの導入を検討してください（そして良いやり方があれば教えてください）</li></ul><h2 id=obs-studioから配信開始>OBS Studioから配信開始</h2><p>OBS Studio側で配信開始ボタンをクリック。
しばらくするとYouTube側の管理画面に配信のプレビューが表示され、YouTube側のライブ配信開始ボタンがアクティブになる。</p><h2 id=youtubeから配信開始>YouTubeから配信開始</h2><p>YouTube側でライブ配信を開始ボタンをクリック。
30秒程度で参加者にライブ配信が見えるようになる。</p><h2 id=配信中>配信中</h2><p>YouTuberとして頑張る。適宜シーンの切り替えやマイクのミュートなど操作が必要です。</p><ul><li>ウィンドウキャプチャの画面がチラつく場合は、OBS Studioがキャプチャするウィンドウの前面に表示されていないかを確認しましょう。
僕の環境では、OBS Studioをこれらより背面に持っていくことでチラツキが解消しました。</li></ul><h2 id=youtubeで配信終了>YouTubeで配信終了</h2><p>YouTube側でライブ配信を終了する。</p><h2 id=obs-studioで配信終了>OBS Studioで配信終了</h2><p>OBS Studio側で配信終了ボタンをクリック。</p><h2 id=配信後>配信後</h2><p>ライブ配信の動画は自動でアーカイブとして公開されます。
アーカイブに残さない場合は、YouTubeのライブ配信の管理画面から削除が必要です。
この辺りは事前に発表者に了承をとっておく必要があると思います。</p><p>動画の編集もYouTubeの管理画面から行えるため、必要に応じて無言の時間などを取り除くことが可能です。</p><p><img src=/images/2020/03/youtube_editor.jpg alt=editor></p><h1 id=初のオンライン配信を終えての感想など>初のオンライン配信を終えての感想など</h1><p>これまでFukuoka.goでは、<a href=https://blog.monochromegane.com/blog/2019/02/23/remote-study-group/>他の地域のコミュニティと拠点間をリモート接続する取り組みは既におこなっており</a>、これをライブ配信に乗せるだけだろうと思っていましたが、それなりに準備や実行で大変だった点や反省点もありました。</p><h2 id=よかった点>よかった点</h2><ul><li>高速な配信環境を準備できた（配信のネットワーク環境は結構重要。家のネットワーク（特に上り）が遅いと配信できないので注意）</li><li>事前に発表者にアーカイブ残すことについてきちんと承諾をもらった</li><li>事前にOBS Studioの設定を終わらせて、当日は起動するだけでよかった</li><li>登壇者はイベント30分前にビデオ会議に集合して画面共有やミュートのルールなどの手順をおさらいした<ul><li>特にGoogle Hangouts Meetの場合、ウィンドウ単位の共有後にプレゼンテーション再生すると画面が真っ暗になる点など</li><li>参考: <a href="https://support.google.com/meet/answer/7290456?hl=ja">ウィンドウを共有すると、プレゼンテーションが空白で表示される</a></li></ul></li><li>事前にオンライン配信のノウハウを仕入れることができた<ul><li><a href=https://youtu.be/87r2N65hm3I>オンラインイベントのノウハウあれこれ</a></li><li>Twitterのタイムラインを横に表示するなども参考にさせていただいた</li></ul></li><li>発表の始まりと終わりはある程度、司会者も音声オンで入っておき盛り上がりを演出できた</li><li>静止画のシーンを用意することでビデオ会議の切り替えなどのもたつきがあっても配信上は見せないようにできた</li></ul><h2 id=反省点>反省点</h2><ul><li>配信準備した環境と配信を行った環境が違ったので設定周りで当日焦った（リハーサル大切&hellip;）<ul><li>画面のチラつき（途中で解消してよかった）</li><li>画面サイズの違い</li></ul></li><li>発表中の登壇者に対して、連絡をとる手段を用意していなかった<ul><li>打鍵音が気になる、発表時間過ぎてるなどを伝えようとするとそれも配信に乗ってしまう</li></ul></li><li>発表中の登壇者がコメントの盛り上がりなどを見るのが難しかった</li><li>Twitterの画面を共有していたが自動更新にならないので手動で更新する手間がかかった</li></ul><p>などです。</p><p>今回の構成は、登壇形式の勉強会において、参加者が視聴する際の敷居を低くすることを目的に設計しました。
参加者にとっては個別のビデオ会議のWebサービスのアカウントが不要ですし、運営者にとってもビデオ会議のアクセス制限や人数制限を気にする必要がありません。
もちろん、勉強会の方式（双方向のディスカッション）によっては他のやり方が最適な場合もあると思います。
そのような場合についてのノウハウも共有してもらえれば嬉しいです。</p><ul><li><a href=https://youtu.be/BIe67vUCnIM>Fukuoka.go#15 + 鹿児島Gophers</a></li></ul></div><footer class=tag><i class="fa fa-tags tag-icon"></i><ul><li><a class=tag-link href=/tags/%E5%8B%89%E5%BC%B7%E4%BC%9A>勉強会</a></li></ul><div class=clear></div></footer></div></article><article><div class=post><header><h1><a href=https://blog.monochromegane.com/blog/2020/01/30/memo-getting-start-reinformation-learning-algorithm/>『強化学習アルゴリズム入門』第1章〜第2章の学習メモ</a></h1><time><div class=day><i class="fa fa-calendar-o day-icon"></i>2020-01-30</div></time></header><div class=post-inner><p>書籍『強化学習アルゴリズム入門』について第1章〜第2章を読んでの学習メモをまとめる。</p><p>強化学習は一連の行動によって得られる報酬を最大化する行動基準を学習する。
そのために、「一連の行動」を状態の遷移と捉えて、その状態に対する価値（状態価値）を求める。
また、各状態には取りうる複数の行動があると考え、その状態の価値を、これらの行動ごとの価値（行動状態価値）から求める。</p><h2 id=強化学習アルゴリズムごとの価値関数>強化学習アルゴリズムごとの価値関数</h2><p>はじめに、第1章〜第2章までで学ぶ各強化学習アルゴリズムの状態価値関数と行動状態価値関数をまとめておく。</p><table><thead><tr><th></th><th>状態価値関数 $V(S_t)$</th><th>行動状態価値関数 $Q(S_t,a_t)$</th></tr></thead><tbody><tr><td>動的計画法</td><td>$V(S_t)=\sum_{a} \pi (a \mid S_t) Q(S_t, a_t) \tag{1}\label{1}$</td><td>$Q(S_t,a_t)=r_{t+1}+\gamma V(S_{t+1}) \tag{2}\label{2}$</td></tr><tr><td>モンテカルロ法</td><td>$V(S_t)=\sum_a Q(S_t,a_t) \frac{N_a}{N} \tag{3}\label{3}$ $V(S_t)=max\{Q(S_t,a_t)\} \tag{4}\label{4}$</td><td>$Q(S_t,a_t)=\frac{1}{m}\sum_{i=1}^{m} G^i(S_t,a_t) \tag{5}\label{5}$ $Q(S_t,a_t) \gets Q(S_t,a_t)+\alpha[G(S_t,a_t)-Q(S_t,a_t)] \tag{6}\label{6}$ where $G(S_t,a_t)=r_{t+1}+\gamma G(S_{t+1},a_{t+1}) \tag{7}\label{7}$</td></tr><tr><td>TD(0)法</td><td>同上</td><td>$Q(S_t,a_t) \gets Q(S_t,a_t)+\alpha[\{r_{t+1}+\gamma(Q(S_{t+1},a_{t+1}))\}-Q(S_t,a_t)] \tag{8}\label{8}$</td></tr></tbody></table><p>以下、各強化学習アルゴリズムについて捕捉する。</p><h2 id=動的計画法>動的計画法</h2><p>確率型ベルマン方程式\eqref{1}に従い行動状態価値を更新する手法。
ここで$\pi (a \mid S_t)$は行動確率であり、方策$\pi$に従い状態$S$において行動$a$を選択する確率を示す。
また、$Q(S_t, a_t)$は行動状態価値関数であり\eqref{2}によって求める。</p><p>行動状態価値関数\eqref{2}は状態$S$において行動$a$によって遷移する状態$S$で得られる報酬$r$とその状態の価値$V$の和によって求められる。
ここで$\gamma$は価値の割引率である。</p><p>書籍ではこの価値の求め方を「将来に対する平均（$X_{t+1}$ から$X_N$ までの平均$\bar{X}$）の逐次的な計算」との類似性によって説明している。
\[
\bar{X_t}=\bar{X}_{t+1}+\frac{1}{N-t}(X_{t+1}-\bar{X}_{t+1})<br>=(\frac{1}{N-t})X_{t+1}+(\frac{N-t-1}{N-t})\bar{X}_{t+1}
\]</p><p>動的計画法における学習プロセスは以下のようになる。</p><h3 id=方策反復法>方策反復法</h3><pre><code>1. 状態価値が収束するまで以下のステップを繰り返す
2. 各状態において方策(行動ごとの行動状態価値Qによるepsilon-greedyなど)に従い行動確率を求める
3. 各状態において行動ごとの行動状態価値を遷移後の状態の報酬と状態価値から求める
4. 2と3よりその状態の状態価値を更新する
5. 全ての状態で状態価値の更新が終わったら次の学習イテレーションへ
</code></pre><h3 id=価値反復法>価値反復法</h3><p>$\epsilon$-Greedyの探索率$\epsilon=0$の場合は方策に依存しない価値反復法となる。</p><pre><code>1. 状態価値が収束するまで以下のステップを繰り返す
2. 各状態において行動ごとの行動状態価値を遷移後の状態の報酬と状態価値から求める
3. 2のうち最大の値で状態の状態価値を更新する
4. 全ての状態で状態価値の更新が終わったら次の学習イテレーションへ
</code></pre><h2 id=モンテカルロ法>モンテカルロ法</h2><p>動的計画法は環境情報が既知の場合に使えるが未知の場合、環境も含めて手探りで行動基準を学習しなければならない。
そのような場合はモンテカルロ法を利用する。</p><p>モンテカルロ法の価値の学習には総報酬$G$\eqref{7}を用いる。
総報酬は一連の行動が終わり得た報酬$r$から遡って状態（と行動）に対して価値を算出する。
書籍ではこの価値の求め方も「将来に対する平均」で表現している（tの値をt+1から求める）。</p><p>なお、行動状態価値は\eqref{5}により試行数$m$での平均とする（学習ステップにおいて\eqref{3}\eqref{4}\eqref{6}は使わない）。</p><p>モンテカルロ法における学習プロセスは以下のようになる。</p><pre><code>1. 任意の試行回数だけ以下のステップを繰り返す
2. 最初の状態から報酬rを得るまで以下のステップを繰り返す
3. 現在の状態において方策(行動ごとの行動状態価値Qによるepsilon-greedyなど)に従い行動aを決定する
4. 次の状態へ遷移
5. 報酬を得たら行動を遡り各状態（と行動）の総報酬Gを求め、試行回数での平均によって行動状態価値Qを更新する
</code></pre><h2 id=td-0-法>TD(0)法</h2><p>モンテカルロ法は総報酬$G$を求めるために必ず一連の行動を終える必要がある。
そこで、逐次的に行動状態価値を求めることでモンテカルロの探索行為を効率的に行おうとするTD(0)法がある。</p><p>TD(0)法では、行動状態価値$Q$を\eqref{8}によって求める。
これは、モンテカルロ法の行動状態価値関数\eqref{5}を逐次計算表現にした\eqref{6}の$G(S_t,a_t)$を動的計画法の行動状態価値関数\eqref{2}で置き換えたものと考えることができる。
つまり、総報酬$G$を$t+1$の報酬と状態価値で近似するものである。</p><p>TD(0)法における学習プロセスは以下のようになる。</p><h3 id=sarsa-方策反復法>SARSA （方策反復法）</h3><pre><code>1. 任意の試行回数だけ以下のステップを繰り返す
2. 最初の状態から報酬rを得るまで以下のステップを繰り返す
3. (S) 現在の状態において方策(行動ごとの行動状態価値Qによるepsilon-greedyなど)に従い行動aを決定、Q(S_t,a_t)を得る
4. (A) 行動aに従い状態を遷移
5. (R) 遷移後の状態で報酬rを得る（得られない時もある）
6. (S) 遷移後の状態において方策に従い行動aを決定、Q(S_t+1,a_t+1)を得る
7. (A) 行動aに従い状態を遷移
8. 5の報酬rと3と6の行動状態価値QでQ(S_t,a_t)を更新
</code></pre><h3 id=q学習-価値反復法>Q学習 （価値反復法）</h3><p>$Q(S_{t+1},a_{t+1})$を$max\{Q(S_{t+1},a_{t+1})\}$で求めることで方策に非依存とする。</p><pre><code>1. 任意の試行回数だけ以下のステップを繰り返す
2. 最初の状態から報酬rを得るまで以下のステップを繰り返す
3. 現在の状態においてランダムに行動aを決定、Q(S_t,a_t)を得る
4. 行動aに従い状態を遷移
5. 遷移後の状態で報酬rを得る（得られない時もある）
6. 遷移後の状態においてランダムに行動aを決定、Q(S_t+1,a_t+1)は全行動状態価値のうち最大の値とする
7. 行動aに従い状態を遷移
8. 5の報酬rと3と6の行動状態価値QでQ(S_t,a_t)を更新
</code></pre><h1 id=学習書籍>学習書籍</h1><iframe style=width:120px;height:240px marginwidth=0 marginheight=0 scrolling=no frameborder=0 src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=monochromeg03-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=427422371X&linkId=e3e609dd57189d2dd910abc95a46bbd0&bc1=ffffff&lt1=_blank&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"></iframe></div><footer class=tag><i class="fa fa-tags tag-icon"></i><ul><li><a class=tag-link href=/tags/%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92>強化学習</a></li></ul><div class=clear></div></footer></div></article><article><div class=post><header><h1><a href=https://blog.monochromegane.com/blog/2020/01/26/exhalation-and-coherently-fittable-system/>テッド・チャン『息吹』と「なめらかなシステム」</a></h1><time><div class=day><i class="fa fa-calendar-o day-icon"></i>2020-01-26</div></time></header><div class=post-inner><p>昨年末にあんちぽさんからお勧めされていた、テッド・チャン『息吹』をようやっと読み終えた。</p><p>本書を通して所属する研究所のビジョンである「なめらかなシステム」の世界観について理解が深まったように感じたのでメモしておく。</p><p>本書は表題の「息吹」を含むSFの短編集である。全部で9編の作品から成る。
多くの作品は、現在の地球の水準より進んだ技術とそれを扱う知性体が登場する。
登場人物は世界を左右するような運命や世界をまたにかける使命など帯びていないどこにでもいるような人々であることが多い。
（『イブの時間』などが雰囲気としては近いかもしれない）
彼ら彼女らはただ、彼らにとっては当然となった新しい技術に起因する変化に彼ら彼女らなりに適応していく。
この技術と変化の設定がリアリティを持っているがゆえに、読者はそう遠くない未来に地球の技術水準が到達した後に発生するであろう変化に対して自分ならばどうするかと没入感を持って作品にのめり込む。</p><p>さて研究所のビジョンとしての「<a href=https://rand.pepabo.com/papers/dicomo2018-proceeding-antipop.pdf>なめらかなシステム</a>」であるが、情報システムとこれを取り巻く要素が互いに影響を及ぼし合う総体としてのシステム観である。
これに対し、以前に「<a href=/blog/2019/03/01/the-things-coherently-fittable-system-looks-ahead-to>なめらかなシステムの見据えるもの。個人的考察</a>」のエントリで、なめらかであることの必然性を問いの発端としてその未来像を検討した。
その際は、「個性」というキーワードで、システムと接する要素が多様かつ継続的に変化することを前提としてこれにシステム側が適応することがこの必然性につながると考えた。
いわば、システムを利用する要素（特に人間）が主でシステムが従のような捉え方であった。
ここで、「なめらかなシステム」自体は、要素間に主従の考えは導入していないにも関わらず、個人の感性としてバイアス的にこのような考えが導入されてしまったと思う。
そのためか、互いに影響を及ぼし合うと言いつつも、システムの利用側としては、そのシステムとそのタスクに限定された影響（例えば、情報要求の前進、あるいは具体化など）程度に収まると考えていた。</p><p>一方で、今回の読書を通して、一段階規模を広げたシステム観に思い至れた。
もし、個別のシステムを超えて、全体としての技術水準やパラダイムのような圧倒的な変化があれば、主従が変化し、そのような技術に追従するために人生観や哲学でさえも（好むと好まざるに関わらず）そこに適応しなければならない。
「なめらかなシステム」においては、ある意味、これまでであれば受け手側が制御不能なレベルでの変化をも適応していきたい。</p><p>今回、単一のシステムから技術、パラダイムの変化にまで拡大してシステム観を適用して考える契機になったと思う。
僕にとって発想を広げるのはSFを読む醍醐味であり、今回の作品は大いにこれが達成されて満足している。
興味を持った方は是非読んで欲しい。
短編集なので1時間程度の空きがあれば少しづつ読み進めることができると思う。
代表作の「息吹」だけでも読んで欲しいし、「ソフトウェア・オブジェクトのライフサイクル」「偽りのない事実、偽りのない気持ち」「オムファロス」「不安は自由のめまい」もお勧めしたい。</p><iframe style=width:120px;height:240px marginwidth=0 marginheight=0 scrolling=no frameborder=0 src="https://rcm-fe.amazon-adsystem.com/e/cm?ref=qf_sp_asin_til&t=monochromeg03-22&m=amazon&o=9&p=8&l=as1&IS2=1&detail=1&asins=4152098996&linkId=c80e18f474ae1d11bcfb8c9f739235ab&bc1=ffffff&lt1=_blank&fc1=333333&lc1=0066c0&bg1=ffffff&f=ifr"></iframe></div><footer class=tag><i class="fa fa-tags tag-icon"></i><ul><li><a class=tag-link href=/tags/%E6%83%85%E5%A0%B1%E8%A6%81%E6%B1%82>情報要求</a></li></ul><div class=clear></div></footer></div></article><a href=/post/ class=archives>Archives</a></div></div><footer class=footer><div class=author></div><p class=author-name><a href=https://twitter.com/monochromegane target=_blank>@monochromegane</a></p><p>monochromegane (モノクロめがね) と申します。</p><p>最近はもっぱらGoに夢中です。普段は研究開発をやっています。</p><ul class=social><li><a href=https://twitter.com/monochromegane target=_blank><i class="fa fa-twitter"></i></a></li><li><a href=https://github.com/monochromegane target=_blank><i class="fa fa-github"></i></a></li><li><a href=/index.xml target=_blank><i class="fa fa-rss"></i></a></li></ul><p class=copyright><small>&copy; <span>Powered by <a href=http://gohugo.io target=_blank>Hugo</a>, Designed by <a href=https://twitter.com/keita_kawamoto target=_blank>&copy;keita_kawamoto</a></span></small></p></footer><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/highlight.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/languages/go.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.6/languages/vim.min.js></script><script>hljs.initHighlightingOnLoad();</script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-38374674-1','auto');ga('send','pageview');</script></body></html>