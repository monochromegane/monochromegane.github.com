<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Wsa研 on THINKING MEGANE</title>
    <link>https://blog.monochromegane.com/tags/wsa%E7%A0%94/</link>
    <description>Recent content in Wsa研 on THINKING MEGANE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Fri, 04 Oct 2019 15:19:40 +0900</lastBuildDate>
    <atom:link href="/tags/wsa%E7%A0%94/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Kaburaya AutoScaler: 多環境での運用性を考慮した自律適応型オートスケーリング制御系</title>
      <link>https://blog.monochromegane.com/blog/2019/10/04/wsa5_kaburaya_autoscaler/</link>
      <pubDate>Fri, 04 Oct 2019 15:19:40 +0900</pubDate>
      
      <guid>https://blog.monochromegane.com/blog/2019/10/04/wsa5_kaburaya_autoscaler/</guid>
      <description>

&lt;p&gt;このエントリは、&lt;a href=&#34;https://websystemarchitecture.hatenablog.jp/entry/2019/07/30/172650&#34;&gt;第五回 Web System Architecture 研究会 (WSA研)&lt;/a&gt;の予稿です。&lt;/p&gt;

&lt;h1 id=&#34;はじめに&#34;&gt;はじめに&lt;/h1&gt;

&lt;p&gt;Webサービスの運用において，急激なアクセス頻度の上昇に対する安定性を保つため，Webアプリケーションにスケーラビリティの仕組みが一般的に求められるようになった．
これを支援するためにWebアプリケーションを稼働させるクラウドサービスやオーケストレーションツールから，オートスケーリング機能が提供されている．
これらのオートスケーリング機能では，開発運用者が予め定めた条件を元にWebアプリケーションの状況が監視される．
そうして，条件を満たせば，開発運用者が予め定めたスケール方法とその実施量に従いWebアプリケーションをスケールさせる．&lt;/p&gt;

&lt;p&gt;このようにオートスケーリングによって，ユーザからのリクエスト数の増減に応じて最適なサーバ台数を調整されることで利用者の快適さと情報システムの運用コストを両立できるようになった．
一方で，オートスケーリングを導入し，継続的に安定した運用するためには開発運用者の運用努力が必要であるが，これらは管理する環境の増加に従い困難になる．
そのため，多環境での運用性を考慮した自動化可能なオートスケーリング戦略が求められる．&lt;/p&gt;

&lt;p&gt;オートスケーリングの継続的に安定した運用に向けた課題は大きく二つある．
一つ目は，アプリケーション特性の把握，二つ目は，“遅れ”の考慮である．&lt;/p&gt;

&lt;h2 id=&#34;課題1-アプリケーション特性の把握&#34;&gt;課題1: アプリケーション特性の把握&lt;/h2&gt;

&lt;p&gt;スケールにはWebアプリケーションを稼働する仮想サーバへリソースを追加する垂直スケール（スケールアップ），稼働する仮想サーバを追加する水平スケール（スケールアウト）の2種類の方法がある．
しかしながら，どちらの方法を用いるにせよ，開発運用者はWebアプリケーションの特性に応じたオートスケーリングの条件やその実施量を予め定める必要がある．
例えば，時刻ベースであればアクセス頻度の時系列的傾向や，リソース変動ベースであればボトルネックとなるメトリクスである．
また，これらの条件に対する必要台数の算出も必要となる．
Webアプリケーションは常に変更が加わることから，手動での継続的な特性の把握と決定は運用負荷の面で現実的ではない．&lt;/p&gt;

&lt;p&gt;そこで，特性把握の自動化が行われている．
三宅らは，過去のアクセス頻度のデータからLSTMを用いて24時間先までの1時間単位のアクセス頻度を予測するモデルを構築し，予測アクセス頻度を元に経験から得られたサーバ単位のスループットにより必要なサーバ台数を求めた[1]．
スループットの把握では，パラメタを連続的に変化させながら最良の結果を得る値を探索的に求める方法も提案されている[2]．
これらの予測的，探索的なアプローチによる特性把握の自動化により，変化する環境に対する追従性は向上する．
一方で，事前的なアプローチであるため，予測の誤差，探索を行った環境と本番環境の誤差に対処できないという課題が残る．&lt;/p&gt;

&lt;p&gt;そのため，三宅らはフィードバック制御による個別の特性把握を必要としないアプローチ[3][4]を提案した．
この手法では，直近のレスポンスタイムが均衡する点に収束するような台数調整によって特性把握が不要で実行時に誤差を修正することができる．
ただし，フィードバック制御を用いるため，制御量であるサーバ台数の決定は探索的である．
待ち行列理論によれば窓口利用率が1を超えると待ち行列は収束しないとされていることから，サーバ台数は即時かつ決定的に求められることが望ましい．&lt;/p&gt;

&lt;h2 id=&#34;課題2-遅れ-の考慮&#34;&gt;課題2: “遅れ”の考慮&lt;/h2&gt;

&lt;p&gt;オートスケーリングでは，本番環境の誤差に対応するための即応的なアプローチを採用すると&amp;rdquo;遅れ&amp;rdquo;の課題が発生する．
一つ目の遅れは，負荷上昇からサーバ台数を見積もるまでの時間差である．
本稿ではこれを「入力の遅れ」と呼ぶ．
次はサーバ台数の変更指示から起動までの時間差である．
本稿ではこれを「出力の遅れ」と呼ぶ．
待ち行列理論によれば窓口利用率が1を超えると待ち行列は収束しないとされていることから，これらの遅れに対して発生した待ちリクエストが系の安定性を崩す．
安定性の低下は開発運用者による不定期な対応を要請し，運用負荷につながることからこれを回避する必要がある．&lt;/p&gt;

&lt;p&gt;そのために，遅れを最小化する手法が適用される．
入力の遅れでは，変化点検出などにより負荷上昇を即時に察知する方式がある．
また，出力の遅れではCRIUを利用することで起動までの時間を短縮する方式[5]がある．
しかしながら，精度の観点やシステム制約によって遅れを0にはできないため，遅れそのものに対する対策は必要となる．&lt;/p&gt;

&lt;p&gt;遅れを踏まえた準備では，前述の予測的なアプローチが考えられる．
三宅らの手法[1]では，予測と事前起動によりこれらの遅れを考慮するが，本番環境の誤差への課題が残る．
そこで，スミスの予測法[6]のようにフィードバック制御において遅れによる影響を踏まえた制御量を算出する手法がある．
一方で，予測のためには精度の高い予測モデルの構築が必要であり，追従にはここの自動化が必須となる．&lt;/p&gt;

&lt;h1 id=&#34;提案手法&#34;&gt;提案手法&lt;/h1&gt;

&lt;p&gt;多環境での運用性を考慮したアプリケーション特性の把握の自動化と安定性の両立のためには，以下の要件が必要となる．&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Webアプリケーション特性として負荷に対する実施量の関係が把握できる&lt;/li&gt;
&lt;li&gt;これを不必要な負荷をかけることなく実行時に自動で把握できる&lt;/li&gt;
&lt;li&gt;把握したWebアプリケーション特性と実環境に誤差が生じた場合に修正できる&lt;/li&gt;
&lt;li&gt;これを実現するリアクティブなアプローチで発生する”遅れ”へ対処できる&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;そこで，フィードフォワード制御を中心とし，実環境の特性把握・追従のためにフィードバック制御を組み込んだ2自由度のオートスケーリング制御系を提案する．
提案手法により，特性把握・追従の自動化ならびに待ち行列理論を用いた決定的な台数算出・遅れ補償による安定化が見込める．
なお，本提案手法の実装はKaburaya AutoScalerとして，OSSでの公開・開発を続けている．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/monochromegane/kaburaya-autoscaler&#34;&gt;monochromegane/kaburaya-autoscaler&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;提案手法では，Webアプリケーション特性を求めるにあたって低負荷時では理想的なレスポンスタイム，高負荷時ではスループット限界を用いることで対象のWebアプリケーションに不必要な負荷をかけることなく現状に即したWebアプリケーション特性を把握することができる．
また，仮想サーバ起動までの遅れに伴う負荷状況を予測し，これを見越した実施量を見積もる遅れ補償機構を設けた．&lt;/p&gt;

&lt;p&gt;提案手法のアーキテクチャを以下に示す．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/65784527-35289080-e18d-11e9-98eb-a155ed8967cc.png&#34; alt=&#34;Kaburaya AutoScaler Architecture&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ここで$F$はフィードフォワード制御部である． 現状の負荷状況に応じて実施量であるサーバ台数を算出する．
算出には待ち行列理論の窓口利用率を求める式を変形した$\lambda/\rho\mu$を用いる．
なお，$\lambda$は平均到着率（req/単位時間），$\mu$は平均サービス率（req/単位時間），$\rho$は窓口利用率を表す．
提案手法では$\rho$には0より大きく1未満の任意の値を設定することができる．&lt;/p&gt;

&lt;p&gt;$P$はプラントであり，$F$で求めたサーバ台数を用いて実際にWebサービスを運用する実環境である．
提案手法では実環境の計測誤差をフィードバックすることで自動かつ継続的な安定性を保つ． $P$は計測結果として単位時間での平均レスポンスタイムである$T_s$と単位時間での1台あたりの処理数である$\mu$を返却する．
これらの値は，$F$における新しい$\mu$に用いられる．&lt;/p&gt;

&lt;p&gt;提案手法では仮想サーバ起動までの遅れに伴う負荷状況を予測し，これを見越した実施量を見積もる遅れ補償機構を設けた．
待ち行列理論では無限時間の平均した待ち時間を求めるため，窓口利用率が1以上の場合に発散し，理論を適用することができない．
一方で，遅れ時間は有限であることから，窓口利用率が1以上の場合であっても待ち行列の長さを求めることができると考えた．
そこで$(\lambda^{t-1}-s^{t-1}\mu^{t-1})\gamma$のように不足処理能力による待ち行列の長さとて加えて，これを捌くことができるサーバ台数を求めている．&lt;/p&gt;

&lt;h1 id=&#34;評価&#34;&gt;評価&lt;/h1&gt;

&lt;p&gt;プラントのシミュレータを使って提案手法によるオートスケーリングの自律・適応の性能を評価した．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/65784472-16c29500-e18d-11e9-9fee-718bac3bbdbd.png&#34; alt=&#34;Evaluation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;右下のグラフにより$\mu$の推定・追従が行えていること，左上のグラフにより遅れ補償が働きアクセス増加時に一時的に多いサーバを投入することで収束できていることが確認できる．
個別の評価についてはスライドを参照されたい．&lt;/p&gt;

&lt;h1 id=&#34;発表スライド&#34;&gt;発表スライド&lt;/h1&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;f71a76ce6cbf454ab583d968916df2b8&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;本研究会ではオートスケーリングと開発運用者間の関係をなめらかにするための多環境での運用を考慮した自律適応型オートスケーリング制御系を提案した．
評価ではM/M/Sモデルを前提としたプラントシミュレータによってこれらが達成可能なことを示した．
実用化に向けて今後はプラントに実際のWebサーバ/アプリケーションサーバを適用した評価や実際の到着，サービス時間間隔に近い分布での評価が必要である．
また，提案手法では入力の遅れに伴い単位時間内に待ちリクエストが必ず発生するため変化点検出などで遅れ時間自体を短縮する方式も検討したい．&lt;/p&gt;

&lt;h1 id=&#34;発表を終えて&#34;&gt;発表を終えて&lt;/h1&gt;

&lt;p&gt;今回のWSA研究会もとても面白かった．
Webシステムアーキテクチャという題材で色々な分野の人が集まって議論することで持ち寄ったアイディアが前進して行くのを何度も見ている．
自分自身の取り組みも研究としてWSA#3からWSA#4を通してGopherConで登壇できるぐらいに育った．
加えて，今回は，オートスケーリングの課題に着目して新しいアプローチを試してみる中で，制御工学や待ち行列理論などを学び楽しめた．
このような普段の研究から少し離れた取り組みであっても，定期的に発表を促されることで形にすることができるのはとても大切で，やりっぱなし学びっぱなしではなく一つの区切りまで考え実装することで次回以降の研究への糧となる．
Webシステムアーキテクチャに関する運用知見を研究的アプローチで前進させること興味がある方は次回開催の参加を検討してみてはいかがでしょうか．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://websystemarchitecture.hatenablog.jp/entry/2017/11/16/182041&#34;&gt;Web System Architecture研究会の発足と挨拶&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://websystemarchitecture.hatenablog.jp/purpose&#34;&gt;研究会の目的&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;リファレンス&#34;&gt;リファレンス&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;[1]: 三宅 悠介, 松本 亮介, 力武 健次, 栗林 健太郎, アクセス頻度予測に基づく仮想サーバの計画的オートスケーリング, FIT 2018 第17回情報科学技術フォーラム, CL-002, Sep 2018.&lt;/li&gt;
&lt;li&gt;[2]: 全自動パラメータチューニングさん &lt;a href=&#34;https://blog.mirakui.com/entry/2013/02/20/003401&#34;&gt;https://blog.mirakui.com/entry/2013/02/20/003401&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[3]: Yusuke Miyake, Optimization for Number of goroutines Using Feedback Control, GopherCon Marriott Marquis San Diego Marina, California, July 2019.&lt;/li&gt;
&lt;li&gt;[4]: 三宅 悠介, Ebira: アクセス負荷に応じて継続的にスケーリング基準を最適化する汎用オートスケーリング機構, 第四回 Webシステムアーキテクチャ研究会, 2019年4月.&lt;/li&gt;
&lt;li&gt;[5]: 松本 亮介, 近藤 宇智朗, CRIUを利用したHTTPリクエスト単位でコンテナを再配置できる低コストで高速なスケジューリング手法, 研究報告インターネットと運用技術（IOT）, Vol.2019-IOT-44, pp.1-8, Feb 2019.&lt;/li&gt;
&lt;li&gt;[6]: O. Smith, &amp;ldquo;Closer control of loops with dead time&amp;rdquo;, Chemical engineering progress, Vol. 53, No. 5, pp. 217-219, 1957.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Ebira: アクセス負荷に応じて継続的にスケーリング基準を最適化する汎用オートスケーリング機構</title>
      <link>https://blog.monochromegane.com/blog/2019/04/14/wsa_4_ebira/</link>
      <pubDate>Sun, 14 Apr 2019 17:33:09 +0900</pubDate>
      
      <guid>https://blog.monochromegane.com/blog/2019/04/14/wsa_4_ebira/</guid>
      <description>

&lt;p&gt;このエントリは、&lt;a href=&#34;https://websystemarchitecture.hatenablog.jp/entry/2019/02/26/100725&#34;&gt;第四回 Web System Architecture 研究会 (WSA研)&lt;/a&gt;の予稿です。&lt;/p&gt;

&lt;h1 id=&#34;はじめに&#34;&gt;はじめに&lt;/h1&gt;

&lt;p&gt;Webサービスの運用において，急激なアクセス頻度の上昇に対する安定性を保つため，Webアプリケーションにスケーラビリティの仕組みが一般的に求められるようになった．
これを支援するためにWebアプリケーションを稼働させるクラウドサービスやオーケストレーションツールから，オートスケーリング機能が提供されている．
しかしながら，機能を利用するためのスケーリング契機となる指標や基準値は，運用するWebサービスの特性を考慮して個別に決定する必要がある．
ホスティングサービスのように個々の運用対象に対する特性が不明かつ多様な環境においては，Webサービスの特性に依存しない汎用的なスケーリング戦略を備えた機構を
横断的に適用できることが，運用効率化並びに運用対象全体での安定化のために重要である．&lt;/p&gt;

&lt;p&gt;Webサービスの特性に依存しない汎用的なスケーリング戦略のためには，汎用的な指標や基準値が必要である．&lt;/p&gt;

&lt;p&gt;Webアプリケーションにおけるアプリケーションサーバは通常，複数のロールのサーバに処理を依頼し，これを統合してリクエストを返すことから，
CPUやメモリといった単一サーバにおけるプリミティブな指標からはその負荷状態を表すことが難しい．
三宅らは&lt;a href=&#34;https://www.ipsj.or.jp/event/fit/fit2018/FIT2018_program_web/data/html/abstract/CL-002.html&#34;&gt;仮想サーバの予測的オートスケーリング&lt;/a&gt;において，
アプリケーションの処理内容ではなく運用経験から得られたサーバ単位のスループットを指標として，これを予測するモデルによってサーバ台数調整機能を実現した．&lt;/p&gt;

&lt;p&gt;一方で基準となる値は運用経験から得られたものであり，運用対象に対する特性が不明な環境では用いることができない．
そこで，この特性を明らかにするために，&lt;a href=&#34;https://blog.mirakui.com/entry/2013/02/20/003401&#34;&gt;「全自動パラメータチューニングさん」&lt;/a&gt;のような探索的なアプローチ，
または，予測的なアプローチが採用される．
しかしながら，ホスティングのような環境では学習データの蓄積を含め，負荷の発生しうる操作の実施には慎重にならざるを得ない．
クラウドサービスやオーケストレーションツールで利用可能な指標の基準値はCPU使用率や秒間クエリ数，コネクション数などシステムが許容可能とみなせる値であり，これらを導くための負荷検証も同様である．&lt;/p&gt;

&lt;p&gt;三宅は&lt;a href=&#34;https://blog.monochromegane.com/blog/2018/11/25/wsa_3_kaburaya/&#34;&gt;Kaburaya: CPU負荷に応じて継続的に上限値を最適化する動的セマフォ&lt;/a&gt;において，
最適な並行数を継続的に求めるために処理対象の負荷の均衡点を目標とする方式を提案した．
この方式では，目標値を動的に変更しフィードバック制御を用いることで，並行数が増えすぎないようにすることができるためオートスケール機能への転用も可能であると述べた． しかしながら，CLIツールを対象とした実装のため，目標値をCPU使用率と定めたこと，一定の負荷が継続的に発生することを前提としたことから，目標値への追従のため継続的に負荷が発生する．&lt;/p&gt;

&lt;p&gt;Webサービスの特性に依存しない汎用的なスケーリング戦略のためには，汎用的な指標として外形的な指標を用いながら，特性に依存しない基準値をWebサービスへの負担なく求めたい．
本研究では，アクセス負荷に応じて継続的にスケーリング基準を最適化する汎用オートスケーリング機構を提案する．
実装には，Kaburayaのうち，ダイナミックターゲットコントローラの仕組みをCPU負荷ではなくWebサービスのレスポンスタイムに対して適用する．
すなわち，直近のレスポンスタイムが均衡する点に収束するような台数調整が行う．
なお，算出する理想台数と実際に追加する台数は分離可能とすることで，ホストのコンピューティングリソースの限界を加味した運用が可能となる．&lt;/p&gt;

&lt;h1 id=&#34;評価&#34;&gt;評価&lt;/h1&gt;

&lt;p&gt;本報告では，提案手法を算出エンジンに用いたシミュレーション環境で評価する．&lt;/p&gt;

&lt;p&gt;シミュレーションは，同時アクセス数によってレスポンスタイムが変化するサーバーによって，水平スケーリングがリニアに有効な状況と
同様の傾向を持つ後段サーバーへのアクセスによるボトルネックが発生し，水平スケーリングがリニアには有効とならない状況を用意した．
これらの環境において，単純なPID制御と比較して，提案手法が前提とする環境において有効であることを示す．&lt;/p&gt;

&lt;h2 id=&#34;シミュレーション環境&#34;&gt;シミュレーション環境&lt;/h2&gt;

&lt;p&gt;同時アクセス数によってレスポンスタイムが変化するサーバーは以下のようにモデル化した．&lt;/p&gt;

&lt;p&gt;$exp(c/el)-1+r$&lt;/p&gt;

&lt;p&gt;ここで，cは同時アクセス数，rは最小レスポンスタイムである．
elは伸長用の定数であり，これが大きければ同時アクセス数の増加に対してレスポンスタイムの増加が繰り延べされる．前段は100，後段は300とした．
なお，後段は水平スケーリングが行われず，前段からのアクセス数の合計が後段に対するアクセス数となり，レスポンスタイムはこれを合算したものとする．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/56059986-804a1500-5da0-11e9-8916-10b66ae6e0ba.png&#34; alt=&#34;expm1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;それぞれのシミュレーション環境の最低な台数とレスポンスタイムを示す．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/56057806-bedcd100-5d9a-11e9-947e-0424283270c9.png&#34; alt=&#34;scalable-noope&#34; /&gt;
&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/56057928-10855b80-5d9b-11e9-8085-b518bfeebdc2.png&#34; alt=&#34;non_scalable-noope&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;水平スケーリングがリニアに有効な場合&#34;&gt;水平スケーリングがリニアに有効な場合&lt;/h2&gt;

&lt;p&gt;PID制御と提案手法の比較を示す．
PID制御は最小レスポンスタイムを平常時の運用において把握したとする．
なお，提案手法では内部にPID制御を用いるが，最適値を動的に求めるため最小レスポンスタイムの把握は不要である．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/56058043-5a6e4180-5d9b-11e9-80af-da6add2d8acd.png&#34; alt=&#34;scalable-pid&#34; /&gt;
&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/56058136-8e496700-5d9b-11e9-9847-2d497f0664ec.png&#34; alt=&#34;scalable-kaburaya&#34; /&gt;&lt;/p&gt;

&lt;p&gt;レスポンスタイムとスケーリングの台数が単純な関係である場合，実装は簡単である．
PID制御は最小レスポンスタイムさえ取得できれば綺麗な適応をする．
一方で提案手法は下げ幅が不足して供給過剰な状態が発生した．
これは目標値の変更を止めるための判定が早期に行われたためであり，間接的には変化率を直前との比較でしか行なっていないことが理由となる．
実運用では，この期間を延伸，さらには移動平均のような形で平滑化してこの精度を向上させる必要がある．&lt;/p&gt;

&lt;h2 id=&#34;ボトルネックがある場合&#34;&gt;ボトルネックがある場合&lt;/h2&gt;

&lt;p&gt;PID制御と提案手法の比較を示す．
最小レスポンスタイムに関する注釈は上記と同じである．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/56058547-a077d500-5d9c-11e9-8c8d-41da2ba4dfdc.png&#34; alt=&#34;non_scalable-pid&#34; /&gt;
&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/56058588-beddd080-5d9c-11e9-9b34-ad8812f8f025.png&#34; alt=&#34;non_scalable-kaburaya&#34; /&gt;&lt;/p&gt;

&lt;p&gt;このシミュレーションではボトルネックに達したことでPID制御によるスケーリングが最小レスポンスに到達しないことで永遠に台数を追加している．
実際にはシステムに最大上限が設けられるが，その最適な上限値についてもWebサービスの特性に依存することから容易に決定することはできない．
一方，提案システムでは，これらの情報を知らずとも目標値の修正によってこれに対処する．
下げ幅の不足については上記と同じ方法での解決が見込める．&lt;/p&gt;

&lt;h1 id=&#34;発表スライド&#34;&gt;発表スライド&lt;/h1&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;70c79a7d33df43f59cb4c9a75aed39df&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;発表を終えて&#34;&gt;発表を終えて&lt;/h1&gt;

&lt;p&gt;今回の発表は前回のアイディアであるKaburayaの具体的な適用箇所を想定したものとした．
個人的な最近の一番の変化だと思っているのが，長期間付き合えるアイディアが出てくるようになったことだ．
長期間付き合えるというのは，1. ビジョンがあって長期間かけてそれらを実現していくもの，2. 汎用的なアイディアがあってそれらの適用先を広げていくもの，の2つがあると思う．
1.については，研究テーマであるなめらかなマッチングに対して一歩づつ進めており，2.についてはWSA研を始めとした個人の興味発のプロダクトがそのようになっている．
特に研究に携わるまでの個人の興味発のプロダクトはたくさんOSSとして公開していたものの，その場限りのもも多く，実際の適用や発展が少なかったように思う．
Kaburayaを始めとする最近のプロダクトでは，なるべく実装から切り離して目的，妥当性，そして背景を整理しながらアーキテクチャ，機構，システムとしての骨組みを整え，自分なりにその本質に迫るようになった．
そして，どのような評価をすればこれらの有効性を示せるかを踏まえた上で実装をする．
これはまさに研究の論文的アプローチであり，これから生まれたプロダクトは以前と比べて芯があり発展性が増してきたように思える．
実際にKaburayaは，WSA研#3での発表を皮切りに東京のGoConで発表し今年サンディエゴであるGopherConにも採択された．そして今回のWSA#4ではオートスケーリングへの転用の可能性も示せた．&lt;/p&gt;

&lt;p&gt;周りを見れば具体と抽象を自在に素早く行き来し，自由闊達かつ高度な意見を交わす人々ばかりで自信を失いかけるけれども，己だけを見た時には多少の成長も感じられるようにはなったと思う．
研究職になってレベルが0になった時期もあったけれども，エンジニアとしての具体化能力との相乗効果が出せるようにこれからも精進して行きたい．&lt;/p&gt;

&lt;p&gt;普段の研究から少し離れながらも研究的なアプローチを進めることができているのはWSA研によるところも大きい．
予稿をブログで書いておけばあとは当日の議論がメインであり，色々な観点からアイディアを練ることができる．このスピード感と濃密感は，エンジニア向けのカンファレンスと学会のいいとこ取りになっている．
定期的にあるところも大変良くて，強制的にアイディアが形になり，進んでいく．&lt;/p&gt;

&lt;p&gt;総じて第四回もとても良い会であった．興味がある方は9月福岡で開催の第五回への参加を検討してみてはいかがだろうか．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kaburaya: CPU負荷に応じて継続的に上限値を最適化する動的セマフォ</title>
      <link>https://blog.monochromegane.com/blog/2018/11/25/wsa_3_kaburaya/</link>
      <pubDate>Sun, 25 Nov 2018 01:28:54 +0900</pubDate>
      
      <guid>https://blog.monochromegane.com/blog/2018/11/25/wsa_3_kaburaya/</guid>
      <description>

&lt;p&gt;このエントリは、&lt;a href=&#34;https://websystemarchitecture.hatenablog.jp/entry/2018/10/09/231937&#34;&gt;第三回 Web System Architecture 研究会 (WSA研)&lt;/a&gt;の予稿です。&lt;/p&gt;

&lt;h1 id=&#34;はじめに&#34;&gt;はじめに&lt;/h1&gt;

&lt;p&gt;マルチコア時代において，単一のマシンで処理性能を最大化するため処理の並行化が行われる．
ノンブロッキングな処理方式の採用によってCPUを効率的に使用する場合には最適な並行数はCPUコア数と等しくなる．
しかしノンブロッキングを実現するランタイム実装の限界から，もしくはノンブロッキングを採用していない場合のような，全体的もしくは部分的にブロッキングが発生する状況においては，最適な並行数の決定は依然として開発者の経験と地道なチューニングに依存している．
このような最適な並行数を求める例としてnginx, unicornのworker_processes，Sidekiqのconcurrency，Goroutineの起動数などが挙げられる．
これらは、実行される処理の負荷や特性がアプリケーションごとに異なるため実行される処理の特性とランタイムやスケジューリングの特性を考慮したチューニングが必要になる．
このような複雑な系に対する普遍的なチューニング手法の発見は困難であることから，これらをブラックボックスとして扱い汎用的に調整できる手法が求められる．&lt;/p&gt;

&lt;p&gt;三宅らは&lt;a href=&#34;https://www.ipsj.or.jp/event/fit/fit2018/FIT2018_program_web/data/html/abstract/CL-002.html&#34;&gt;仮想サーバの予測的オートスケーリング&lt;/a&gt;において，アプリケーションの処理内容ではなく運用経験から得られたサーバ単位のスループットを指標として，これを予測するモデルによってサーバ台数調整機能を実現した．
また，&lt;a href=&#34;https://blog.mirakui.com/entry/2013/02/20/003401&#34;&gt;「全自動パラメータチューニングさん」&lt;/a&gt;ではメトリクスを一点に絞りスループットが最大化する値を探索的に求める．
これらの手法は指標を限定しても充分な成果が得られることを示した．一方でその求め方は予測的または探索的であり，Webサーバープロセスのように比較的長期稼働する場合に適用可能である．
しかしながらCLIのような短期稼働かつ性能が求められるようなプロセスにおいては予測や探索は利用できない．
これらの利用用途に対応するため，指標の限定に加え，反応的かつ誤差が少なく指標へ追従する手法が必要である．&lt;/p&gt;

&lt;p&gt;本研究では，処理やランタイムの特性に依存せずに，マシンの負荷に応じて反応的かつ継続的に，並行数を最適化する手法を検討する．
まず，最適な並行数を求めるために，最適化の手法としてフィードバック制御を用いる．指標にはノンブロッキングな処理方式がCPUを効率的に利用することに着目し，CPU使用率を採用する．
次に，並行数の制御にはセマフォを採用することで提案手法に汎用性を持たせる．
本報告では，ノンブロッキングな処理方式をランタイムとして採用するGo言語において，CPU負荷に応じて継続的に上限値を最適化する動的セマフォを実現するライブラリを開発し，これを評価する．&lt;/p&gt;

&lt;h1 id=&#34;実装&#34;&gt;実装&lt;/h1&gt;

&lt;p&gt;フィードバック制御を用いてGoroutineの起動数を動的に調整する手法を実装するためには，ある時点で最適なGoroutineの起動数をフィードバック制御によって決定する仕組みと，その起動数を制約としてGoroutineの起動数を制御する仕組みが必要となる．
このような並行処理の起動数を制御する仕組みには一般的にセマフォが利用される．Go言語ではセマフォとしてバッファ付きチャンネルを用いるのが定石となっている．
そこで本研究では，最適なセマフォの値をフィードバック制御によって動的に変更可能な仕組みを構築した．なおこの実装はOSSの&lt;a href=&#34;https://github.com/monochromegane/kaburaya&#34;&gt;kaburaya&lt;/a&gt;として公開している．&lt;/p&gt;

&lt;h2 id=&#34;制御器&#34;&gt;制御器&lt;/h2&gt;

&lt;p&gt;本研究では，ある時点で最適なGoroutineの起動数をフィードバック制御によって決定する仕組みを制御器と呼ぶ．
今回，制御器の設計についてはGoroutine起動数が制御可能な入力となる．これによって対象のスループットを最大化するのが目的である．しかしながら実行される処理の負荷や特性が異なっても共通に採用できる固定値のスループット値は事前に求めることはできないため別の指標を用いる必要がある．
本研究ではいくつかの制御器の評価を通して効果的な制御器を求める．
以降，Go言語ランタイムがI/Oブロッキングな処理についてもGoroutineの切り替えにより、その負荷をCPU側に移動させることから，CPU負荷が安定になることが一つの上限とみなせると仮定していくつかの制御器を設計する．&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;初期値からワーカー数を変えないFixController (比較用)&lt;/li&gt;
&lt;li&gt;CPU使用率100%を目標値とし，不足した場合は workerを1ずつ増加させる SimpleController&lt;/li&gt;
&lt;li&gt;CPU使用率100%を目標とし，目標との差分のK倍を加える PController(比例制御)&lt;/li&gt;
&lt;li&gt;3.のCPU使用率の目標値を90%としたもの&lt;/li&gt;
&lt;li&gt;直近3観測点の平均を目標値として3観測ごとにPControllerの目標値を変化させるDynamicController&lt;/li&gt;
&lt;li&gt;一定期間のCPU使用率の標準偏差をとってそれが一定の値以下だったら安定したとみなして，workerを減らしていくStabilityController&lt;/li&gt;
&lt;li&gt;CPU使用率ではなくてCPU使用率の変化率を元に制御するRateController&lt;/li&gt;
&lt;li&gt;5.のDynamicControllerを元に定期ではなく大きな変動ごとに目標値を見直す方式&lt;/li&gt;
&lt;li&gt;8.のDynamicControllerを元に定常時の不要なworkerを削減する方式&lt;/li&gt;
&lt;li&gt;9.のDynamicControllerを元に変動の精度と速度を向上させるために積分微分制御を導入する方式&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;セマフォ&#34;&gt;セマフォ&lt;/h2&gt;

&lt;p&gt;本研究では，制御器によって決定された起動数を制約としてGoroutineの起動数を制御する仕組みをセマフォと呼ぶ．
今回のセマフォの要件としてはセマフォの上限値が動的に変更可能であること，そして通常のセマフォと同様にP操作において値が負になる場合に実行がブロックされる．またこれらの値の変更がアトミックに行われる必要がある．&lt;/p&gt;

&lt;p&gt;これらはGo言語では二つのチャンネルを組み合わせることで実現可能である．すなわち，それぞれのチャンネルからの入力と出力でセマフォの値を更新し，必要に応じて内部でチャンネルへの操作の有効無効を切り替えることで結果的に利用者側に対するブロック処理を実現する．&lt;/p&gt;

&lt;h1 id=&#34;評価&#34;&gt;評価&lt;/h1&gt;

&lt;p&gt;本研究では，設計した制御器の出力する起動数が最適であることを検証する．ここで最適であるとは，処理対象のタスク全体を，最低限の，のべ起動数で，最短の時間で処理できる起動数を指す．
評価には，汎用性と再現可能性を高めるため，以下の機能を持つシミュレーターを用いる．&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;シミュレータは実時間ではなく，単位時間をステップとみなす&lt;/li&gt;
&lt;li&gt;JobはWorkloadを持ち，ステップごとのCPU利用率を定義する&lt;/li&gt;
&lt;li&gt;Workloadが0のステップはブロッキング処理を表現する&lt;/li&gt;
&lt;li&gt;シミュレータはステップごとに任意の数のジョブを投入する&lt;/li&gt;
&lt;li&gt;シミュレータはステップごとに起動可能なワーカー数を制御器から取得する&lt;/li&gt;
&lt;li&gt;ワーカーはシミュレータで利用可能なCPU利用率までジョブの該当ステップのWorkloadを消費する&lt;/li&gt;
&lt;li&gt;消費できなかったWorkloadは次回のステップに回される&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Workloadが0のステップはCPU資源を消費しないため無条件にステップを進める&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;現状はスイッチングコストがシミュレータに反映できていない．&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;JobにはCPUビジーとなる処理，多くのシステムコールが発生する処理，ネットワークのような長期間のブロッキングが発生する処理などを再現したものを投入する．&lt;/p&gt;

&lt;p&gt;設計した制御器に対する主な評価結果は以下のとおり&lt;/p&gt;

&lt;h2 id=&#34;シミュレーション1&#34;&gt;シミュレーション1&lt;/h2&gt;

&lt;p&gt;初期値からワーカー数を変えないFixControllerによって固定値での最適なワーカー数を求めた．今回のシミュレーションではworker:7 ぐらいが最適と考えられる．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/48418118-d4bc7a80-e797-11e8-8ec1-7eb3456aedc5.png&#34; alt=&#34;result&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;シミュレーション2&#34;&gt;シミュレーション2&lt;/h2&gt;

&lt;p&gt;CPU使用率100%を目標値とし，不足した場合はworkerを1ずつ増加させるSimpleControllerでは，ジョブが多く投入される初期段階においてワーカー数の増加が追いつかないことからジョブ全体の処理がシミュレーション1と比較して長くなってしまっている．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/48418271-3250c700-e798-11e8-884b-0b7ba7be65ff.png&#34; alt=&#34;result&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;シミュレーション4&#34;&gt;シミュレーション4&lt;/h2&gt;

&lt;p&gt;CPU上限を目標値とした場合に制御器の出力が負にならないため，ワーカー数を削減することができない．そこでCPU使用率90%を目標とした．CPU上限に達した場合に不要なワーカー数を削減する一方で，目標値が固定のため，ジョブが完了し，CPU使用率が低下した場合にも反応してしまった．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/48418723-57920500-e799-11e8-8cf8-4a06837bfb1e.png&#34; alt=&#34;result&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;シミュレーション5&#34;&gt;シミュレーション5&lt;/h2&gt;

&lt;p&gt;目標値が固定であることからジョブ完了後にワーカー数を増加し続けてしまう問題に対応するためCPU使用率の目標値自体を変動させることとする．
本シミュレーションでは，CPU使用率が均衡する時点をワーカー数の上限であると仮定し，直近3観測点の平均を目標値として3観測ごとに制御器の目標値を変化させるDynamicControllerを実装評価した．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/48453796-39a7bd00-e7f8-11e8-9d00-5332f3a94450.png&#34; alt=&#34;result&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;シミュレーション9&#34;&gt;シミュレーション9&lt;/h2&gt;

&lt;p&gt;CPU使用率やジョブ実行状況にできるだけ速く追従するため，一定間隔ごとに目標値を見直すのではなく，CPU使用率の変動があった時点で目標値を変更する．
大きな増減を契機に調整していく仕組みになったことで，CPU安定時に積極的にワーカーを削減することができるようになった&lt;/p&gt;

&lt;p&gt;以下では目標値の変動を赤でプロットしている．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/48612283-e9815400-e9cb-11e8-884a-955a73006986.png&#34; alt=&#34;result&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;シミュレーション11&#34;&gt;シミュレーション11&lt;/h2&gt;

&lt;p&gt;頻繁に変更される目標値に高速かつ誤差が少なく適応していくため古典的制御手法であるPID制御を導入した．
調整の結果，本シミュレーションではPID制御のゲインとしてKp: 0.1, Ki: 0.5, Kd: 0.5が有効であった．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/48614179-ff454800-e9d0-11e8-8c39-ad66450984f8.png&#34; alt=&#34;result&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/48614371-6ebb3780-e9d1-11e8-84f3-8a73dc4670e3.png&#34; alt=&#34;result&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;その他のシミュレーション&#34;&gt;その他のシミュレーション&lt;/h2&gt;

&lt;p&gt;検討段階の各シミュレーション結果については&lt;a href=&#34;https://gist.github.com/monochromegane/5e9fc94371a9b2385eedd38d98341e6b#gistcomment-2758500&#34;&gt;こちら以降のコメント欄&lt;/a&gt;を参照のこと．
制御器の実装の番号とシミュレーション番号が同じにしている．&lt;/p&gt;

&lt;p&gt;また，実環境で同様のジョブを用いた評価結果について今回は間に合わず未評価である．&lt;/p&gt;

&lt;h1 id=&#34;まとめ&#34;&gt;まとめ&lt;/h1&gt;

&lt;p&gt;本研究では，処理やランタイムの特性に依存せずに，マシンの負荷に応じて反応的かつ継続的に，並行数を最適化する手法として，CPU負荷に応じて継続的に上限値を最適化する動的セマフォを提案した．
また，シミュレーション環境においてではあるが，ノンブロッキングな処理方式を前提とする場合に有効なCPU使用率の目標値を負荷情報に応じて変動させる制御器として設計することができた．
本方式はCPU使用率とセマフォというランタイムや実装に依存しない方式を採用しているため，並行数を求めなければならない様々な場面に適用可能であると考える．
今後の課題として，実環境での評価としてGo言語のGoroutineの起動数に対する評価が必要である．
また，制御器のパラメタ設計も課題として挙げられるが，フィードバック制御という歴史ある分野の蓄積を有効的に活用することで解決したい．&lt;/p&gt;

&lt;h1 id=&#34;発表スライド&#34;&gt;発表スライド&lt;/h1&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;b5541b4887f14681ab89e2bd97f13bdd&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;発表を終えて&#34;&gt;発表を終えて&lt;/h1&gt;

&lt;p&gt;第三回のWSA研も様々な観点からの提案と活発な議論が交わされる有意義な場であったと思う．
特にrrreeeyyyさんの&lt;a href=&#34;https://speakerdeck.com/rrreeeyyy/a-survey-of-anomaly-detection-methodologies-for-web-system&#34;&gt;A survey of anomaly detection methodologies for web system&lt;/a&gt;は業務で得た知識をサーベイ論文と組み合わせて再体系化していく非常に興味深い試みで，サービス運用者が参考にしていくべき取り組みだと思えた．
自分自身の研究発表では，個人的な開発時の課題であるGoroutine起動数のチューニングという課題から，研究を意識して問いを抽象化することで，実装に囚われない多角的な解決策を講じることができた点が良かったと思う．質疑では本手法が活きる場面を整理できていなかったことに気づけたことでもう一段先に進めた．
自身のアイディアや実装など狭い範囲から視点を広げるのは難しいことではあるが，こうして研究会を契機に継続的に訓練していくことで少しづつでも前に進んでいると思えるのはとても嬉しい．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sanny: 大規模ECサイトのための精度と速度を両立した分散可能な近似近傍探索エンジン</title>
      <link>https://blog.monochromegane.com/blog/2018/05/16/wsa_2_sanny/</link>
      <pubDate>Wed, 16 May 2018 16:14:09 +0900</pubDate>
      
      <guid>https://blog.monochromegane.com/blog/2018/05/16/wsa_2_sanny/</guid>
      <description>

&lt;p&gt;このエントリは、&lt;a href=&#34;http://websystemarchitecture.hatenablog.jp/entry/2018/03/22/104006&#34;&gt;第二回 Web System Architecture 研究会 (WSA研)&lt;/a&gt;の予稿です。&lt;/p&gt;

&lt;h1 id=&#34;はじめに&#34;&gt;はじめに&lt;/h1&gt;

&lt;p&gt;ECサイトの商品種類増大に伴う情報過多問題を解決するため，利用者の要求を満たす商品を自動的に提案する機能がECサイトにとっての関心事となる．商品の提案は任意の観点での商品同士の類似性を根拠とすることから，商品の特性を数値化し，任意の距離空間で近傍に位置する要素を求めることで，機械的に扱えるようにする．この数値化された商品特性を特徴量と呼ぶ．
深層ニューラルネットワークの発展によって，これまで適切な特徴量を導くことが難しかった画像やテキストに対しても，人の感性に近い，特性をよく表現する高精度な特徴量を得られるようになったことからECサイトの商品提案機能に利用され始めている．
これらの深層ニューラルネットワークから得られる特徴量は，数百から数千次元の高次元ベクトルとして表現される．
また，大規模なECサイトでは提案対象となる商品数も多いため，この特徴量の集合も数十から数百万を超える大規模なものとなる．
このような大規模かつ高次元ベクトル集合に対する類似度の比較において，正確ではあるが，データ数と次元数に比例して計算量が増加する線形探索は現実的ではない．そこで，事前に近傍候補となる集団を求めておくことで，少数の近傍候補から計算量を抑えて近傍点を得る空間分割や局所性鋭敏型ハッシュといった手法が用いられる．
しかしながら，高次元ベクトル集合においては正確な近傍を求めるための計算量が線形探索と同程度となると考えられており，精度を犠牲にして近似解を用いることで計算量の増加に対処する近似近傍探索が採用されているが，商品を自動的に提案する機能は、提案内容の的確さと充分な応答速度が求められることから，大規模かつ高次元ベクトル集合に対して精度と速度を両立する近似近傍探索の手法が必要となる．&lt;/p&gt;

&lt;p&gt;大規模かつ高次元ベクトル集合に対する近似近傍探索では，データ数と次元数に依存して計算量が増加するため，これらを分割して処理することが効果的である．
ベクトル集合を行列と見なし，行方向での分割，つまりデータ数によって分割する手法は一般に採用されるが，依然として次元数に依存した計算量の課題は残る．
そこで，列方向での分割が必要となる．
直積量子化は，高次元ベクトル集合を任意の次元数の低次元ベクトル集合に等分し，各低次元ベクトル集合に対する近傍探索結果を集約する．
しかしながら，集約処理はデータ数に依存するという課題がある．&lt;/p&gt;

&lt;p&gt;そこで，本報告では，大規模ECサイトで商品を提案することを想定して，精度と速度を両立した分散可能な近似近傍探索エンジンSannyを提案する．
Sannyは，商品特性をよく表現しており高精度に類似度が比較可能な高次元かつ密なベクトルの集合において，検索質問データ(クエリ)に対する高次元ベクトル集合の近傍探索結果の上位集合が，クエリと高次元ベクトル集合を任意の次元数で等分した部分ベクトル単位で近傍探索した結果の上位集合と類似しやすいことに着目して，提案すべき商品の近傍探索を部分ベクトル単位での探索に分解することで分散処理可能にし，その探索結果の和集合である近傍候補から再度近傍探索を行うことにより，全体として高速に近似近傍探索を行える．&lt;/p&gt;

&lt;h1 id=&#34;提案手法&#34;&gt;提案手法&lt;/h1&gt;

&lt;h2 id=&#34;事前準備&#34;&gt;事前準備&lt;/h2&gt;

&lt;p&gt;提案手法ではまず，商品特性をよく表現しており高精度に類似度が比較可能な高次元かつ密なベクトルの集合を対象とする．
このような集合として，学習済み深層畳み込みニューラルネットワークを特徴抽出器として利用して画像から得られる特徴量集合や，テキストを分散表現へ変換するWord2vecのネットワークから得られる特徴量集合がある．
筆者らはこれらの集合において，検索質問データ(クエリ)に対する高次元ベクトル集合の近傍探索結果の上位集合が，クエリと高次元ベクトル集合を任意の次元数で等分した部分ベクトル単位で近傍探索した結果の上位集合と類似しやすい特性があることを見出した．
この，高次元ベクトルで表現される特徴量のうち，部分が類似しているものは全体としても類似する可能性が高いという特性を利用することで，高次元ベクトル集合を列方向に分割した結果の集約のデータ数依存の課題を解決する．&lt;/p&gt;

&lt;p&gt;ここでは，対象となるベクトル集合を$Y \subset \mathbb{R}^D$と置き，これを重複しない$D^*=D/m$次元の部分ベクトル$S_j(1 \leq j \leq m)$に分割する．&lt;/p&gt;

&lt;h2 id=&#34;近傍探索&#34;&gt;近傍探索&lt;/h2&gt;

&lt;p&gt;Yに対する近傍探索は次のように行う．
クエリベクトル$q \in \mathbb{R}^D$を$p_j (1 \leq j \leq m)$に分割し，対応する添え字$j$の部分ベクトル集合$s_j$に対して上位$n$件を得る近傍探索を行う．&lt;/p&gt;

&lt;p&gt;\begin{align}
NN(p_j) = \argmin_{s \in S_j} d(p_j,s)
\end{align}&lt;/p&gt;

&lt;p&gt;$NN(p_j)$の結果を$n$個の識別子からなる集合$N_j$とし，全ての$N_j$の和集合を$N$としてこれを近傍候補とする．なお，距離関数には現時点でユークリッド距離を想定しているが，すべての部分ベクトルで統一されていれば近傍探索の手法自体は問わない．&lt;/p&gt;

&lt;p&gt;最後に近傍候補$N$に対応する元のベクトル集合 $YN \subset \mathbb{R}^D$ に対して正確な類似度を比較するためにクエリベクトル$q$との線形探索を行う．$|YN|$は最大$n*m$であることから線形探索のコストは非常に小さいが，距離関数にユークリッド距離を用いる場合，以下で求まる近似的な線形探索を用いることで一層の高速化が見込める．&lt;/p&gt;

&lt;p&gt;\begin{align}
argmin_a (a - b)^2 = argmin_a a^2 - 2ab + b^2 = argmin_a a^2 - 2ab
\end{align}&lt;/p&gt;

&lt;h2 id=&#34;システム構成&#34;&gt;システム構成&lt;/h2&gt;

&lt;p&gt;提案手法では，探索対象となる高次元ベクトル集合を任意の次元数で等分した部分ベクトルに分割する．これらの部分ベクトルに対する近傍探索は互いに独立していることから並列に処理することができるため，データ数や次元数に応じた分散構成を取ることができる．
分散構成では，部分ベクトルの近傍探索結果$N_j$がネットワーク上でやり取りされるが，前述のように最小限のデータ量のみが通信されることからネットワーク通信における影響を抑えることができる．なお，大規模なECサイトにおいては大量のクエリが想定されることから，HTTP/2のバイナリフレームレイヤーのように通信の多重化を行うことで影響を抑える手法も合わせて導入する．&lt;/p&gt;

&lt;p&gt;また，分散構成では，データを重複して保持することで，可用性も高めることができる．&lt;/p&gt;

&lt;h1 id=&#34;評価&#34;&gt;評価&lt;/h1&gt;

&lt;h2 id=&#34;速度と精度による性能評価&#34;&gt;速度と精度による性能評価&lt;/h2&gt;

&lt;p&gt;以下に，2048次元，40,000件程度の高次元ベクトル集合に対して提案手法と従来手法の精度と速度のバランスを比較した予備実験の結果を示す．横軸は再現率であり，各手法の提示した予測近傍集合と正しい近傍集合との重複率である．縦軸は検索にかかった秒数の逆数を取ったもので，上にあるほど高速である．
従来手法として，線形探索(brute_force)，近似線形探索(brute_force_blas)，近似近傍探索(annoy)と比較した．提案手法は，近傍候補から正確な近傍を求めるために用いた手法ごとに評価を行なっている．&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://user-images.githubusercontent.com/1845486/39663980-251292b2-50b7-11e8-84ce-b072f4c42e3a.png&#34; alt=&#34;sanny&#34; /&gt;&lt;/p&gt;

&lt;p&gt;結果から，近傍候補からの探索に近似線形探索を用いた場合の提案手法が従来の近似近傍探索手法より精度並びに速度でも有効であることを示している．&lt;/p&gt;

&lt;h1 id=&#34;発表スライド&#34;&gt;発表スライド&lt;/h1&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;892943b4cfe14595ae1f5df01386389e&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;発表を終えて&#34;&gt;発表を終えて&lt;/h1&gt;

&lt;p&gt;大規模なデータセットでの評価，事前分類による推薦との差など研究報告としてはまだ新規性や有用性の面で示しきれていない箇所もあったが，そこも含めて議論ができてよかったと思う．特にGPU環境での評価や，データ数や次元数への依存が少ないと思われるLSHなどの手法への適用など具体的に差を示すべき箇所が浮かんできたのが収穫である．サーベイ並びに評価を進めたい．&lt;/p&gt;

&lt;p&gt;WSA研は，事業で研究的なアプローチをどう活かすかを普段から考えて実際に成果を出している人々が集まっている．研究成果とサーベイを携えて次はどう論述するかについて吸収し，次回は誰かに影響を与えられるようになれたら良いなと思う．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>分散アプリケーションにおける複数端末利用を考慮したプライベートデータの管理</title>
      <link>https://blog.monochromegane.com/blog/2017/12/25/wsa_1_kaleidoscope/</link>
      <pubDate>Mon, 25 Dec 2017 15:53:07 +0900</pubDate>
      
      <guid>https://blog.monochromegane.com/blog/2017/12/25/wsa_1_kaleidoscope/</guid>
      <description>

&lt;p&gt;このエントリは、&lt;a href=&#34;http://websystemarchitecture.hatenablog.jp/entry/2017/12/17/133301&#34;&gt;第一回 Web System Architecture 研究会 (WSA研)&lt;/a&gt;の予稿です。&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;af69192ff1d84cd8967df33363605ccb&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;1-はじめに&#34;&gt;1. はじめに&lt;/h1&gt;

&lt;p&gt;ブロックチェーン技術の登場により、インターネットを経由した個人間での直接の価値交換が容易となりつつある。&lt;/p&gt;

&lt;p&gt;これまで、インターネット上での個人間での価値交換の場を提供してきた、マーケットプレイス型のECサイトや、シェアリングエコノミーの代表である、&lt;a href=&#34;https://www.airbnb.jp/&#34;&gt;Airbnb&lt;/a&gt;や&lt;a href=&#34;https://www.uber.com/ja-JP/&#34;&gt;Uber&lt;/a&gt;は、一旦情報を集約し提供する仲介者としてのビジネスを行ってきた。これらのビジネスはニーズのマッチングと取引の信頼性の提供の二つの側面で価値を提供している。一方、ブロックチェーンは、非中央集権的な台帳管理をトランザクションの順序性を明確にするデータ構造とブロック生成と検証に系が正しく回るような仕組みを組み込むことで、信頼性の提供を実現する。このように中央集権的な存在を介さないブロックチェーン上で動作するBitCoinやEthereumが通貨や契約機構としての役割を備えることでボーダレスかつ多様性を持った直接の価値交換が可能な仕組みが整ってきた。&lt;/p&gt;

&lt;p&gt;実際に、&lt;a href=&#34;https://storj.io/&#34;&gt;Storj&lt;/a&gt;や&lt;a href=&#34;https://filecoin.io/&#34;&gt;Filecoin&lt;/a&gt;といったストレージの空き容量を価値へと交換する分散型ファイルストレージサービスや、P2P上でマーケットプレイスを開設しBitCoinで支払いを行う&lt;a href=&#34;https://www.openbazaar.org/&#34;&gt;OpenBazzar&lt;/a&gt;などが登場している。&lt;/p&gt;

&lt;p&gt;これらの価値交換プラットフォームは自律しており、中央集権的な運用やサーバーが存在しない。言い換えれば参加者全員がサーバーでありクライアントである。このような非中央集権的な価値交換プラットフォームの登場は従来型のWebサービス提供者に対してパラダイムシフトを迫るものである。&lt;/p&gt;

&lt;p&gt;本研究報告では、非中央集権的な価値交換プラットフォームにおけるアプリケーション実装の考察を行い、用途別データ管理、特にプライベートデータの取り扱いの方式について検討する。&lt;/p&gt;

&lt;h1 id=&#34;2-分散アプリケーションにおけるプライベートデータ管理の課題&#34;&gt;2. 分散アプリケーションにおけるプライベートデータ管理の課題&lt;/h1&gt;

&lt;p&gt;非中央集権的な価値交換プラットフォームにおけるアプリケーション実装は、中央集権的なサーバーが存在しないため、従来のアプリケーション実装方式は適用できない。そこで、本章でははじめに、非中央集権的なアプリケーション実装の方式とそれらの課題について述べる。&lt;/p&gt;

&lt;p&gt;なお、本章以降、非中央集権的な価値交換プラットフォームにおけるアプリケーション、すなわち中央の管理を受けない自律分散型のアプリケーションのことを分散アプリケーションと呼ぶこととする。DAppsとして提唱されている分散アプリケーションとは異なることに留意されたい。&lt;/p&gt;

&lt;h2 id=&#34;2-1-分散アプリケーションの実装と用途別データ管理&#34;&gt;2.1 分散アプリケーションの実装と用途別データ管理&lt;/h2&gt;

&lt;p&gt;従来の中央集権的なサービスは、サーバー、クライアント方式をとるが、分散アプリケーションではアプリケーションやデータはその分散ネットワークに参加する個々の端末に分散される。&lt;/p&gt;

&lt;p&gt;例えば、P2PファイルシステムとBitCoinを用いたマーケットプレイスを提供する分散アプリケーションであるOpenBazzarの構成は以下のようになる。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;商取引の履歴はブロックチェーン上に保存&lt;/li&gt;
&lt;li&gt;商品の情報はP2Pファイルシステム上に保存&lt;/li&gt;
&lt;li&gt;利用者の情報は端末に保存&lt;/li&gt;
&lt;li&gt;アプリケーションはローカルで起動し、上記のデータをつなぐ&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ブロックチェーンはその信頼性から、分散アプリケーションが重要とみなす取引の履歴を保存する。しかしながら、台帳記載に手数料がかかること、ブロックの確定にタイムラグがあることなどから重要度の低いデータや更新の多い情報はブロックチェーンの外側で管理される。また、取引自体が発生しないマスタデータなども台帳管理としては不適切である。つまり、分散アプリケーションでは用途に応じて管理されるデータを組み合わせて利用する必要がある。&lt;/p&gt;

&lt;h2 id=&#34;2-2-分散アプリケーションにおけるプライベートデータ共有の課題&#34;&gt;2.2 分散アプリケーションにおけるプライベートデータ共有の課題&lt;/h2&gt;

&lt;p&gt;分散アプリケーションに必要なデータの多くは非中央集権な仕組みで分散されるため、その分散ネットワークに参加できる環境において、どの端末からも比較的容易にアクセス可能である。一方、利用者の情報は各端末に保存されるため、複数端末で環境を揃えるためには端末間でデータを共有する必要がある。本研究では、従来のデータ共有モデルの検討を通して、分散アプリケーションにおけるプライベートなデータ共有の課題を示す。&lt;/p&gt;

&lt;h3 id=&#34;2-2-1-分散ファイルシステムとデータベース&#34;&gt;2.2.1 分散ファイルシステムとデータベース&lt;/h3&gt;

&lt;p&gt;マウント処理を通してサーバー上のデータ操作を透過的に行うことができるNFSや、端末上で操作したファイルがサーバー上に自動的に同期されるDropboxのようなアプリケーション、そしてデータを一元管理するデータベースサーバーなどは典型的な中央集権的なデータ共有であると言える。また、URLによって相互にドキュメントを参照する広大なドキュメントベースシステムとして捉えるとWWWもデータ共有の仕組みとみなすことができるが、各ドキュメントはサーバー単位で管理されており、これもまた、中央集権的なデータ共有となっている。&lt;/p&gt;

&lt;p&gt;これらの手法は中央集権的なアプリケーション実装において利用されているが、非中央集権的な構成をとる分散アプリケーションの実装においては、これらの中央集権的な仕組みに依存しないことが望ましい。&lt;/p&gt;

&lt;h3 id=&#34;2-2-2-p2p型データベース&#34;&gt;2.2.2 P2P型データベース&lt;/h3&gt;

&lt;p&gt;Amazon DynamoDBやApache CassandraはP2P型の分散データベースであり、クラスタリングされた各ノードがデータを分散して保存する。これらのデータベースへのノード追加やデータアクセスは中央集権的にコントロールされており、基本的には閉じた専用のネットワークとして構築、運用される。&lt;/p&gt;

&lt;p&gt;分散アプリケーションの実装においては、中央集権的な仕組みに依存しない開けたP2P型のネットワークであることが望ましい。また、そのネットワークは耐障害性や利便性の観点から参加ノードの多い、普及したネットワークであるとより良い。&lt;/p&gt;

&lt;h3 id=&#34;2-2-3-p2p型分散ファイルシステム&#34;&gt;2.2.3 P2P型分散ファイルシステム&lt;/h3&gt;

&lt;p&gt;非中央集権的なデータ共有としてP2Pネットワークを用いた分散ファイルシステムがある。データはP2Pネットワーク上のノードに分散して保存され、利用者は何らかのポインタによりそれらにアクセスする。&lt;a href=&#34;https://ipfs.io/&#34;&gt;IPFS(InterPlanetary File System)&lt;/a&gt;は、P2Pネットワークを用いたドキュメントベースのデータ共有モデルである。データの分散保存とデータ内容に基づくアドレッシングにより、従来のWWWのサーバー依存を取り除き、非中央集権的なデータ共有を可能にしている。また、IPFSはディレクトリ構造も扱うことができるため、端末のデータ構造との親和性が高いことも特徴である。&lt;/p&gt;

&lt;p&gt;データ内容に基づくアドレッシングの場合、内容の変更がアドレスの変更につながるため、利用者は最新のアドレスを保持しておくことが求められる。なお、IPFSではIPNSと呼ばれる、固定アドレスと任意のアドレスを紐づけることができる名前解決の仕組みも提供することでこの問題の解決を図っている。&lt;/p&gt;

&lt;p&gt;また、IPFSを始めとするP2P型分散ファイルシステムは、ネットワーク参加者にデータの内容が参照されてしまう。プライベートデータの共有のためには、データ参照を制限する仕組みが求められる。&lt;/p&gt;

&lt;h3 id=&#34;2-2-4-p2p分散ファイルシステム上のデータストア&#34;&gt;2.2.4 P2P分散ファイルシステム上のデータストア&lt;/h3&gt;

&lt;p&gt;汎用的なP2P型分散ファイルシステム上でデータベースファイルを管理することでデータ共有を行う手法がある。IPFSを始めとするP2P型分散ファイルシステムはデータ内容に基づくアドレッシングを行うため、ファイル内容の一部変更であっても別データと見なされる。そのため、Sqliteなどの従来のデータベースファイルを直接配置すると変更の度に全データがP2P上に保存し直されることになる。これはデータ容量が大きくなるにつれて深刻なオーバーヘッドとなる。&lt;/p&gt;

&lt;p&gt;そのため、P2P型分散ファイルシステムの特性を考慮したデータベースが必要となる。つまり変更の局所化であり、修正内容に対するP2P上への保存量が少ないほど良い。&lt;a href=&#34;https://github.com/orbitdb/orbit-db&#34;&gt;OrbitDB&lt;/a&gt;はIPFS上で動作するデータストアであり、データストアへのデータ追加更新削除などの操作内容履歴の一つづつをIPFS上にファイルとして保存することで変更を局所化する。&lt;/p&gt;

&lt;p&gt;また、複数端末での利用を考えると、データの競合への対処が必要となる。分散データ管理におけるCAP定理では、CAPの全てを満たすことは難しいとされているが、このうち、APを満たすデータ構造であるCRDTが知られている。CRDTはデータが順不同であることを前提とし、データ操作を可換なものに限定することで参照整合性を提供する。先ほど紹介したOrbitDBも複数のデータストア種別においてこれをサポートしている。&lt;/p&gt;

&lt;p&gt;なお、参照時はこれらの可換な操作の履歴を統合したものが利用されるが、履歴の増加に伴い参照時のオーバーヘッドが発生する。実運用ではメモリ上に展開しておくなどの工夫が必要となる。&lt;/p&gt;

&lt;h1 id=&#34;3-分散アプリケーションにおけるプライベートデータ管理手法の提案&#34;&gt;3. 分散アプリケーションにおけるプライベートデータ管理手法の提案&lt;/h1&gt;

&lt;p&gt;ここまで、従来のデータ共有モデルを比較しながら、分散アプリケーションにおけるプライベートデータ管理に求められる要件を抽出した。要件は以下の通りである。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1. 非中央集権的な構成であること&lt;/li&gt;
&lt;li&gt;2. 分散保存されるデータに対して参照制限をかけれること&lt;/li&gt;
&lt;li&gt;3. 開かれた普及しているP2P型ネットワークを用いること&lt;/li&gt;
&lt;li&gt;4. 最新のアドレスを保持または解決できること&lt;/li&gt;
&lt;li&gt;5. 変更が局所化されていること&lt;/li&gt;
&lt;li&gt;6. 変更の競合に対応できること&lt;/li&gt;
&lt;li&gt;7. 参照時のオーバーヘッドが少ないこと&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3.以降はP2P型分散ファイルシステム利用にあたって必要となる要件である。本研究報告では、これらを満たす手法として&lt;a href=&#34;https://github.com/monochromegane/kaleidoscope&#34;&gt;Kaleidoscope&lt;/a&gt;と名付けたOSSを実装、公開した。以降、Kaleidoscopeの構造と機能を示していく。&lt;/p&gt;

&lt;p&gt;なお、文中の[*N]は上記要件番号と対応するものとする。&lt;/p&gt;

&lt;h2 id=&#34;3-1-提案手法の構造&#34;&gt;3.1 提案手法の構造&lt;/h2&gt;

&lt;p&gt;KaleidoscopeはP2P分散ファイルシステム上で動作するKey-Value Storeである。データ共有モデルとしては、前述のP2P分散ファイルシステム上のデータストアに分類される[*1]。また、P2PネットワークとしてはIPFSを想定している[*3]。&lt;/p&gt;

&lt;p&gt;Kaleidoscopeのデータ構造は至ってシンプルである。データストア名、キー名をディレクトリとし、内容をファイルとするディレクトリ構造をIPFS上に保存する。データはタイムスタンプ等のメタデータと内容を合わせて暗号化が成される。暗号化は公開鍵方式で行われるため、秘密鍵の所有者以外は内容を把握できない[*2]。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;├── __database_name
├── key1
│   └── value
└── key2
    └── value
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Kaleidoscopeはデータストアと対応するディレクトリ構造の変更を内部で保持するだけでなく、IPNSを用いて固定されたデータストアのアドレスから最新のアドレスを解決する[*4]。&lt;/p&gt;

&lt;p&gt;以上の仕組みにより、利用者はKaleidoscopeを用いて、キーとディレクトリアドレスとの対応、暗号化と復号化、最新のアドレスの解決を意識することなく、透過的に個人用のKey-Value Storeを扱うことができる。&lt;/p&gt;

&lt;p&gt;次に、KaleidoscopeがP2P分散ファイルシステム上のデータストアの課題を解決する手法を紹介する。従来のP2P分散ファイルシステム上のデータストアは、ファイルシステムの特性を考慮しないファイルベース差分方式とOrbitDBに代表されるオペレーションベース差分方式と考えることができる。&lt;/p&gt;

&lt;p&gt;Kaleidoscopeはデータストアをディレクトリ構造で表現することでこれを解決するディレクトリベース差分方式を提案、採用する。&lt;/p&gt;

&lt;p&gt;ディレクトリベース差分方式での値の更新はキー単位に分離されており、データストア全体のデータ容量に依存しない[*5]。また、更新後のディレクトリ構造のアドレスを参照するため、常に最新の値を更新履歴に依存せず取得することができる[*7]。さらに値を表現するファイル内容にタイムスタンプを持つことで、ディレクトリ構造としての統合が可能になる[*6]。CRDTの思想に添えば、順不同な可換な操作を統合できればよく、必ずしも全履歴を保持する必要はないためである。&lt;/p&gt;

&lt;h2 id=&#34;3-2-提案手法の機能&#34;&gt;3.2 提案手法の機能&lt;/h2&gt;

&lt;p&gt;Kaleidoscopeの基本的な利用方法を以下に示す。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# IPFSデーモンの起動
$ ipfs daemon

# Kaleidoscope CLIによるIPFS操作
$ kes
&amp;gt; create my-db
# =&amp;gt; データストア用の鍵ペアの作成とディレクトリをIPFSに登録
&amp;gt;
&amp;gt; set key1 value1
# =&amp;gt; IPFSに暗号化して保存
&amp;gt;
&amp;gt; get key1
value1
# =&amp;gt; IPFSの該当するディレクトリ構造からファイルを取得し復号化する
&amp;gt;
&amp;gt; save
# =&amp;gt; 最新のハッシュ値でIPNSを更新する
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;端末間の共有に対しては&lt;code&gt;use&lt;/code&gt;コマンドを利用し、最新のハッシュ値を得ることができる。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ kes
&amp;gt; use my-db
# =&amp;gt; IPNSから最新のハッシュ値を得る
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ただし、現状の実装ではIPNS更新に数秒かかるため、リアルタイムに端末間でデータを同期することが難しい。そこで、IPFSのPubSub機能を利用して変更の操作履歴を共有する&lt;code&gt;sync&lt;/code&gt;コマンドを実験的に用意した。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# PubSubオプションを指定してIPFSデーモンの起動
$ ipfs daemon --enable-pubsub-experiment

$ kes
&amp;gt; sync
# =&amp;gt; 以降、オンラインの他の自身の端末からの操作履歴が共有される
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;現状、&lt;code&gt;sync&lt;/code&gt;コマンドは操作履歴としてコマンド並びに対象となったファイルのハッシュ値をPubSub経由で送信する。受信側は、自身の操作にそれらの操作を差し込みながら順番に処理を行う。正確な実装ではタイムスタンプまで考慮した統合が必要であり、今後の対応案件である。&lt;/p&gt;

&lt;p&gt;また、マージ処理は現状未実装であり、これも今後の対応案件である。&lt;/p&gt;

&lt;h1 id=&#34;4-評価&#34;&gt;4. 評価&lt;/h1&gt;

&lt;h2 id=&#34;4-1-差分方式による更新時間の比較&#34;&gt;4.1 差分方式による更新時間の比較&lt;/h2&gt;

&lt;p&gt;まず、差分方式による更新時間の差を比較する。シナリオとして、1MBの値を繰り返し登録した際のIPFS上への登録時間を計測した（単位は秒）。ファイルベース差分方式では、値の蓄積に伴いファイル容量が増加するため当然ながら登録処理が遅くなる。オペレーションベースとディレクトリベースでは変更が局所化しているため、データストア全体の値の蓄積に処理時間が依存しないことがわかる。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;size(MB)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;file-based&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ope-based&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;dir-based&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.017593&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.021435&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.028095&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.040661&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.023311&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.031242&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.048258&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.026174&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.030879&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.073272&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.023378&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.026437&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.101438&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.022118&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.040008&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.073841&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.028761&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.032161&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.093803&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.025831&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.038100&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.092051&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.023874&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.026611&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.110011&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.026290&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.026626&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.116614&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.025109&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.031673&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;なお、ディレクトリベースでは、値の更新時にルートディレクトリの更新処理が発生するため、その追加処理分だけ、オーバーヘッドが発生していることから、ファイルベース差分と比較して時間がかかっていると考えられる。&lt;/p&gt;

&lt;h2 id=&#34;4-2-差分方式による初期起動時間の比較&#34;&gt;4.2 差分方式による初期起動時間の比較&lt;/h2&gt;

&lt;p&gt;次に、差分方式による初期起動時間の差を比較する。シナリオとして、1MBの値が繰り返し登録されている状態のデータストアに対して初期起動の時間を計測した（単位は秒）。ファイルベースとオペレーションベースでは現在の情報を一旦読み込む必要があるため、蓄積されたデータに初期起動時間が比例する。ただし、オペレーションベース差分方式では、各操作履歴の取得は並行できるので、実装の工夫により短縮することは可能である。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;size(MB)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;file-based&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;ope-based&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;dir-based&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.003264&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.002369&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.004155&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.005634&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.006680&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.007669&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.007542&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.011732&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.008023&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.012052&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.019605&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.015466&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.072510&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.019542&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013462&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.018007&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.011672&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.027935&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.021468&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.026011&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;なお、ディレクトリベース差分方式では、最新のデータストアがIPFS上に存在するため、初期起動時の読み込みは不要である。&lt;/p&gt;

&lt;h2 id=&#34;4-3-差分方式によるマージ時間の比較&#34;&gt;4.3 差分方式によるマージ時間の比較&lt;/h2&gt;

&lt;p&gt;現時点で未実装。ディレクトリベースでは競合するデータベースごとに最新の値を持っているので、操作ログを全て比較するオペレーションベースに対して優位であると想定する。&lt;/p&gt;

&lt;h1 id=&#34;5-まとめ&#34;&gt;5. まとめ&lt;/h1&gt;

&lt;p&gt;非中央集権的な直接の価値交換プラットフォームの進出により、分散アプリケーションの実装が増えるに伴い課題となるプライベートデータ共有について、従来手法を比較し、最も適していると考えられるP2P分散ファイルシステムを用いたデータストアが抱える課題をディレクトリベース差分方式により解決する手法を提案した。
ディレクトリベースのデータ構造は単純なKey-Valueだけでなくサブディレクトリを設けることで利用可能なデータ構造の拡張が見込めるため今後の実装を進めていきたい。
また、現在の実装ではデータ共有をIPNS更新とPubSubによるリアルタイム同期で行なっているが、それぞれ、保存処理に時間がかかること、対応する端末が常にネットワークに存在する必要があるという課題がある。今後、最新のアドレス履歴をバッファリングされて時間差で参照できるような仕組みにより、より快適に利用できる仕組みを検討していきたい。&lt;/p&gt;

&lt;h1 id=&#34;参考文献&#34;&gt;参考文献&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Giuseppe DeCandia, Deniz Hastorun, Madan Jampani, Gunavardhan Kakulapati,
Avinash Lakshman, Alex Pilchin, Swaminathan Sivasubramanian, Peter Vosshall
and Werner Vogels, Dynamo: Amazon’s Highly Available Key-value Store,  In Proceedings of twenty-first
ACM SIGOPS symposium on Operating systems principles, ACM Press New York, NY, USA, pp. 205–220, 2007&lt;/li&gt;
&lt;li&gt;Julian Browne, Brewer&amp;rsquo;s CAP Theorem - The kool aid Amazon and Ebay have been drinking, 2009&lt;/li&gt;
&lt;li&gt;Mihai Letia and Nuno M. Preguiça and Marc Shapiro, CRDTs: Consistency without concurrency control, CoRR, 2009&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;発表を終えて&#34;&gt;発表を終えて&lt;/h1&gt;

&lt;p&gt;時間調整をミスって持ち時間のうちほとんどを発表に当ててしまい、議論を存分にできなかったのが心残り。実際に発表の練度が低かったので、前提の共有もうまく行かず失敗したなあとしばらく落ち込んでしまった。次回はきちんと仕上げてきます。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
